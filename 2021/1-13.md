
# 2021-1-13

### error read: http://120.53.237.72:1200/zhihu/zhuanlan/chicken-life

### error read: http://www.bigdatainterview.com/feed/

### [全球贸易体系大变局与我国农业国际竞争战略取向](http://www.jintiankansha.me/t/24QmRHbURv)

### [在生物演化过程中先有的大脑还是先有的睡眠？](http://jandan.net/p/108337)

### [在自然环境里散步，令我们步履轻盈](http://jandan.net/p/108321)

### [中国科学家得到了Ia型超新星的首个完整光谱](http://jandan.net/p/108329)

### [WHO提示：2021年群体免疫没戏](http://jandan.net/p/108336)

### [圣地亚哥动物园中多只大猩猩确诊新冠](http://jandan.net/p/108334)

### [【招聘】Bifrost团队招聘！！！](https://rustcc.cn/article?id=94dc3fae-2bbc-4328-8646-37fc0211027d)

### [【Geometric effects of certain system design choices】网页链接 某些系统设计选择的几何影响。 [图片]](https://weibo.com/1715118170/JCTO5o0li)

### [【Why we need wide adoption of social recovery wallets】网页链接 为什么我们需要广泛采用社会康复钱包？ [图片][图片][图片][图片][图片]](https://weibo.com/1715118170/JCTBJcx6F)

### [#绿洲摄影#梦幻雪乡☃️ 童话般的世界 绿洲 [图片]](https://weibo.com/1715118170/JCTrnDl5e)

### [【Evidence for entropy maximisation in human free choice behaviour】网页链接 人类自由选择行为中熵最大化的证据。 [图片]](https://weibo.com/1715118170/JCTpQuu8b)

### [一般在哪买国产的车厘子（樱桃）？](https://www.v2ex.com/t/744108)

### [PNAS Paper: Deep learning will transform entomology](https://www.reddit.com/r/DeepLearningPapers/comments/kvzain/pnas_paper_deep_learning_will_transform_entomology/)

 <!-- SC_OFF --><div class="md"><p>Maybe some of you will find the application of deep learning in ecology/entomology interesting.</p> <p>Entomology is not just dusty old museum collections and insects on needles (nothing wrong with either). It is also cutting-edge technology, big data and AI. The vast number of insect species and the challenging task of studying them makes entomology the perfect playground for collaborative efforts, in this case between biologists, statisticians, and mechanical, electrical and software engineers. In the paper, we demonstrate the relevance of high-tech solutions in entomological research.</p> <p><a href="https://www.pnas.org/content/118/2/e2002545117">Paper: Deep learning will transform entomology</a></p> <p>&#x200b;</p> <p><a href="https://preview.redd.it/5e5193hliya61.png?width=1145&amp;format=png&amp;auto=webp&amp;s=d5de3fd9a15e46e765b020d636482ff3abbe9c01">https://preview.redd.it/5e5193hliya61.png?width=1145&amp;format=png&amp;auto=webp&amp;s=d5de3fd9a15e46e765b020d636482ff3abbe9c01</a></p> <p>Disclaimer: Co-author of paper.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/HjalteM"> /u/HjalteM </a> <br /> <span><a href="https://www.reddit.com/r/DeepLearningPapers/comments/kvzain/pnas_paper_deep_learning_will_transform_entomology/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/DeepLearningPapers/comments/kvzain/pnas_paper_deep_learning_will_transform_entomology/">[comments]</a></span>

### [Google Research: Looking Back at 2020, and Forward to 2021](http://feedproxy.google.com/~r/blogspot/gJZg/~3/80Gya-tEqYI/google-research-looking-back-at-2020.html)

 <span class="byline-author">Posted by Jeff Dean, Senior Fellow and SVP of Google Research and Health, on behalf of the entire Google Research community</span> <p>When I joined Google over 20 years ago, we were just figuring out how to really start on the journey of making a high quality and comprehensive search service for information on the web, using <a href="https://americanhistory.si.edu/press/fact-sheets/google-corkboard-server-1999">lots of curiously wired computers</a>. Fast forward to today, and while we’re taking on a much broader array of technical challenges, it’s still with the same overarching goal of organizing the world's information and making it universally accessible and useful. In 2020, as the world has been reshaped by COVID-19, we saw the ways research-developed technologies could help billions of people better communicate, understand the world, and get things done. I’m proud of what we’ve accomplished, and excited about new possibilities on the horizon. </p><p>The goal of <a href="http://research.google">Google Research</a> is to work on long-term, ambitious problems across a wide range of important topics —  from predicting the spread of COVID-19, to designing algorithms, to learning to translate more and more languages automatically, to mitigating bias in ML models. In the spirit of our annual reviews for <a href="https://ai.googleblog.com/2020/01/google-research-looking-back-at-2019.html">2019</a>, <a href="http://ai.googleblog.com/2019/01/looking-back-at-googles-research.html">2018, </a>and more narrowly focused reviews of some work in <a href="https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html">2017</a> and <a href="https://ai.googleblog.com/2017/01/the-google-brain-team-looking-back-on.html">2016</a>, this post covers key Google Research highlights from this unusual year. This is a long post, but grouped into many different sections. Hopefully, there’s something interesting in here for everyone!  For a more comprehensive look, please see our <a href="https://research.google/pubs/?year=2020">&gt;750 research publications in 2020</a>. </p><p><b>COVID-19 and Health</b><br />As the impact of COVID-19 took a tremendous toll on people’s lives, researchers and developers around the world rallied together to develop tools and technologies to help public health officials and policymakers understand and respond to the pandemic. <a href="https://blog.google/inside-google/covid-19/exposure-notifications-end-year-update/">Apple and Google partnered in 2020</a> to develop the Exposure Notifications System (ENS), a Bluetooth-enabled privacy-preserving technology that allows people to be notified if they have been exposed to others who have tested positive for COVID-19. ENS supplements traditional contact tracing efforts and has been deployed by public health authorities in more than 50 countries, states and regions to help curb the spread of infection. </p><p>In the early days of the pandemic, public health officials signalled their need for more comprehensive data to combat the virus’ rapid spread. Our <a href="https://www.google.com/covid19/mobility/">Community Mobility Reports</a>, which provide anonymized insights into movement trends, are helping researchers not only understand the <a href="https://science.sciencemag.org/content/369/6510/1465">impact of policies</a> like stay-at-home directives and social distancing, and also conduct <a href="http://documents1.worldbank.org/curated/en/619261589478136374/pdf/Nowcasting-Economic-Activity-in-Times-of-COVID-19-An-Approximation-from-the-Google-Community-Mobility-Report.pdf">economic forecasting</a>.  </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-R07J48BgUxY/X_3V-eRcmhI/AAAAAAAAG68/CFU8r3EYIpYv3E80iSpAhlX4FxIBbWIVgCLcBGAsYHQ/s812/image6.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="301" src="https://1.bp.blogspot.com/-R07J48BgUxY/X_3V-eRcmhI/AAAAAAAAG68/CFU8r3EYIpYv3E80iSpAhlX4FxIBbWIVgCLcBGAsYHQ/w400-h301/image6.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Community Mobility Reports: Navigate and download a report for regions of interest.</td></tr></tbody></table><p>Our own researchers have also explored using this anonymized data to<a href="https://arxiv.org/pdf/2007.03113.pdf"> forecast COVID-19 spread</a><span style="text-decoration: underline;"> </span>using graph neural networks instead of traditional time series-based models. </p><p>Although the research community knew little about this disease and secondary effects initially, we’re learning more every day. Our <a href="https://blog.google/technology/health/using-symptoms-search-trends-inform-covid-19-research/">COVID-19 Search Trends symptoms</a> allows researchers to explore temporal or symptomatic associations, such as anosmia — the loss of smell that is sometimes a symptom of the virus. To further support the broader research community, we launched <a href="https://blog.google/technology/health/google-health-studies-app/">Google Health Studies app</a> to provide the public ways to participate in research studies. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-wpRzHNSVXNo/X_3WGGe4dyI/AAAAAAAAG7A/9mXi4nwA3skgDkTX77N0fxzVXcLgb6YUgCLcBGAsYHQ/s1252/image21.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="279" src="https://1.bp.blogspot.com/-wpRzHNSVXNo/X_3WGGe4dyI/AAAAAAAAG7A/9mXi4nwA3skgDkTX77N0fxzVXcLgb6YUgCLcBGAsYHQ/w400-h279/image21.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Our COVID-19 Search Trends are helping researchers study the link between the disease’s spread and symptom-related searches.</td></tr></tbody></table><p>Teams across Google are contributing tools and resources to the <a href="https://blog.google/technology/health/making-data-useful-public-health/">broader scientific community</a>, which is working to address the health and economic impacts of the virus. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-V-Nkzhfetco/X_3WN6crwgI/AAAAAAAAG7E/0BXitr2DBfQZIUqO2KMPSxZBjLgD8DFxACLcBGAsYHQ/s979/image23.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://1.bp.blogspot.com/-V-Nkzhfetco/X_3WN6crwgI/AAAAAAAAG7E/0BXitr2DBfQZIUqO2KMPSxZBjLgD8DFxACLcBGAsYHQ/w394-h400/image23.png" width="394" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">A spatio-temporal graph for <a href="https://arxiv.org/pdf/2007.03113.pdf">modelling COVID-19 Spread.</a></td></tr></tbody></table><p>Accurate information is critical in dealing with public health threats. We collaborated with many product teams at Google in order to improve information quality about COVID-19 in Google News and Search through supporting <a href="https://www.blog.google/outreach-initiatives/google-news-initiative/covid-19-65-million-help-fight-coronavirus-misinformation/">fact checking efforts</a>, as well as similar efforts in <a href="https://blog.youtube/news-and-events/expanding-fact-checks-on-youtube-to-united-states">YouTube</a>. </p><p>We helped multilingual communities get equal access to critical COVID-19 information by <a href="https://nextstrain.org/sars-cov-2">sponsoring localization of Nextstrain.org’s weekly Situation Reports</a> and <a href="https://translatorswithoutborders.org/TICO-19-announcement">developing a COVID-19 open source parallel dataset in collaboration with Translators Without Borders</a>. </p><p>Modelling a complex global event is particularly challenging and requires more comprehensive <a href="https://github.com/GoogleCloudPlatform/covid-19-open-data">epidemiological datasets</a>, the development of <a href="https://research.google/pubs/pub49500/">novel interpretable models</a> and <a href="https://github.com/google-research/agent-based-epidemic-sim">agent-based simulators</a> to inform the public health response. Machine learning techniques have also helped in other ways from deploying <a href="https://ai.googleblog.com/2020/05/an-nlu-powered-tool-to-explore-covid-19.html">natural language understanding</a> to helping researchers quickly navigate the mountains of COVID-19 scientific literature, applying <a href="https://arxiv.org/abs/2009.01265">anonymization technology</a> to protect privacy while making useful datasets available, and exploring whether public health can conduct faster screening with fewer tests via <a href="https://ai.googleblog.com/2020/07/exploring-faster-screening-with-fewer.html">Bayesian group testing</a>. </p><p>These are only a sample of the many pieces of work that happened across Google to help users and public health authorities respond to COVID-19. For more, see <a href="https://health.google/covid-19/">using technology to help take on COVID-19</a>. </p><p><b>Research in Machine Learning for Medical Diagnostics</b><br />We continue to make headway helping clinicians harness the power of ML to deliver better care for more patients. This year we have described notable advances in applying computer vision to aid doctors in the diagnosis and management of cancer, including helping to make sure that doctors <a href="http://ai.googleblog.com/2020/08/using-machine-learning-to-detect.html">don’t miss potentially cancerous polyps during colonoscopies</a>, and showing that an ML system <a href="https://blog.google/technology/health/using-ai-identify-aggressiveness-prostate-cancer/">can achieve substantially higher accuracy than pathologists in Gleason grading of prostate</a> tissue, enabling radiologists <a href="https://blog.google/technology/health/improving-breast-cancer-screening/">to achieve significant reductions in both false negative and false positive results when examining X-rays for signs of breast cancer</a>. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-N8Tknh68Mx8/X_3W6KzpqwI/AAAAAAAAG7U/7V1tBrVrg3cNcN83AzEqnFIWlgjwJzJ7ACLcBGAsYHQ/s941/image25.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="255" src="https://1.bp.blogspot.com/-N8Tknh68Mx8/X_3W6KzpqwI/AAAAAAAAG7U/7V1tBrVrg3cNcN83AzEqnFIWlgjwJzJ7ACLcBGAsYHQ/w400-h255/image25.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">To determine the aggressiveness of prostate cancers, pathologists examine a biopsy and assign it a <a href="https://en.wikipedia.org/wiki/Gleason_grading_system">Gleason grade</a>. In published research, our system was able to grade with higher accuracy than a cohort of pathologists who have not had specialist training in prostate cancer. The first stage of the deep learning system assigns a Gleason grade to every region in a biopsy. In this biopsy, green indicates Gleason pattern 3, while yellow indicates Gleason pattern 4.</td></tr></tbody></table><p>We’ve also been working on systems to help identify <a href="https://www.nature.com/articles/s41591-020-0842-3">skin disease</a>, help detect <a href="https://blog.google/technology/health/predicting-sight-threatening-eye-condition/">age-related macular degeneration</a> (the leading cause of blindness in the U.S. and U.K., and the third-largest cause of blindness worldwide), and on potential novel non-invasive diagnostics (e.g., being able to detect signs of <a href="https://blog.google/technology/health/anemia-detection-retina/">anemia from retinal images</a>). </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-_T5LS2KOcmI/X_3XC17Nw7I/AAAAAAAAG7Y/OsY92L8K49wUAQm-Jk6359s29iHFWgG8QCLcBGAsYHQ/s1000/image20.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="156" src="https://1.bp.blogspot.com/-_T5LS2KOcmI/X_3XC17Nw7I/AAAAAAAAG7Y/OsY92L8K49wUAQm-Jk6359s29iHFWgG8QCLcBGAsYHQ/w640-h156/image20.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Our study examines how a deep learning model can quantify hemoglobin levels — a measure doctors use to detect anemia — from retinal images.</td></tr></tbody></table><p>This year has also brought exciting demonstrations of how these same technologies can peer into the human genome. Google’s open-source tool, DeepVariant, identifies genomic variants in sequencing data using a convolutional neural network, and this year won the <a href="https://ai.googleblog.com/2020/09/improving-accuracy-of-genomic-analysis.html">FDA Challenge for best accuracy in 3 out of 4 categories</a>. Using this same tool, a <a href="https://jamanetwork.com/journals/jama/article-abstract/2772962?guestAccessKey=39889aad-2894-4380-b869-5704ed2f9f6b">study led by the Dana-Farber Cancer Institute</a> improved diagnostic yield by 14% for genetic variants that lead to prostate cancer and melanoma in a cohort of 2,367 cancer patients.  </p><p>Research doesn’t end at measurement of experimental accuracy. Ultimately, truly helping patients receive better care requires understanding how ML tools will affect people in the real world. This year we began work with Mayo Clinic to develop a machine learning system to assist in <a href="https://blog.google/technology/health/exploring-ai-radiotherapy-planning-mayo-clinic/">radiotherapy planning</a> and to better understand how this technology could be deployed into clinical practice. With our partners in Thailand, we’ve used diabetic eye disease screening as a test case in how we can build systems with <a href="https://blog.google/technology/health/healthcare-ai-systems-put-people-center/">people at the center</a>, and recognize<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/jmri.27476"> the fundamental role of diversity, equity, and inclusion</a> in building tools for a healthier world. </p><p><b>Weather, Environment and Climate Change</b><br />Machine learning can help us better understand the environment and make useful predictions to help people in both their everyday life as well as in disaster situations. For weather and precipitation forecasting, computationally intensive physics-based models like NOAA’s <a href="https://rapidrefresh.noaa.gov/hrrr/">HRRR</a> have long reigned supreme. We have been able to show, though, that ML-based forecasting systems <a href="https://ai.googleblog.com/2020/01/using-machine-learning-to-nowcast.html">can predict current precipitation with much better spatial resolution</a> (“<em>Is it raining in my local park in Seattle?”</em> and not just “<em>Is it raining in Seattle?”</em>) and <a href="https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html">can produce short-term forecasts of up to eight hours</a> that are considerably more accurate than HRRR, and can compute the forecast more quickly, yet with higher temporal and spatial resolution. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-XpdA2VpNTao/X_3YirKNWHI/AAAAAAAAG7k/1vEqadLi-XMrT94lCm5CRc7DDF07PhfYQCLcBGAsYHQ/s1415/image1.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="198" src="https://1.bp.blogspot.com/-XpdA2VpNTao/X_3YirKNWHI/AAAAAAAAG7k/1vEqadLi-XMrT94lCm5CRc7DDF07PhfYQCLcBGAsYHQ/w640-h198/image1.gif" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">A visualization of predictions made over the course of roughly one day. <b>Left:</b> The 1-hour HRRR prediction made at the top of each hour, the limit to how often HRRR provides predictions. <b>Center:</b> The ground truth, i.e., what we are trying to predict. <b>Right:</b> The predictions made by our model. Our predictions are every 2 minutes (displayed here every 15 minutes) at roughly 10 times the spatial resolution made by HRRR. Notice that we capture the general motion and general shape of the storm.</td></tr></tbody></table><p>We’ve also <a href="https://ai.googleblog.com/2020/09/the-technology-behind-our-recent.html">developed an improved technique called HydroNets</a>, which uses a network of neural networks to model the actual river systems in the world to more accurately understand the interactions of upstream water levels to downstream inundation, resulting in more accurate water-level predictions and flood forecasting. Using these techniques, we've expanded <a href="https://blog.google/technology/ai/flood-forecasts-india-bangladesh/">our coverage of flood alerts by 20x in India and Bangladesh</a>, helping to better protect more than 200 million people in 250,000 square kilometers.  </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-m6xgWaHZGeE/X_3YrISe6MI/AAAAAAAAG7o/BJ65Nbtz6i8MlfffH214hn7jjrWvYnRZgCLcBGAsYHQ/s640/image11.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://1.bp.blogspot.com/-m6xgWaHZGeE/X_3YrISe6MI/AAAAAAAAG7o/BJ65Nbtz6i8MlfffH214hn7jjrWvYnRZgCLcBGAsYHQ/w400-h400/image11.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">An illustration of the HydroNets architecture.</td></tr></tbody></table><p>Better analysis of satellite imagery data can also give Google users a <a href="https://blog.google/products/search/mapping-wildfires-with-satellite-data/">better understanding of the impact and extent of wildfires</a> (which caused devastating effects in California and Australia this year). We showed that automated analysis of satellite imagery can help with <a href="https://ai.googleblog.com/2020/06/machine-learning-based-damage.html">rapid assessment of damage after natural disasters</a> even with <a href="https://arxiv.org/abs/2011.14004">limited prior satellite imagery</a>. It can also aid <a href="https://www.blog.google/products/earth/helping-cities-seed-new-trees-with-tree-canopy-lab/">urban tree-planting efforts</a> by helping cities assess their current tree canopy coverage and where they should focus on planting new trees. We’ve also shown how <a href="https://ai.googleblog.com/2020/06/leveraging-temporal-context-for-object.html">machine learning techniques that leverage temporal context</a> can help improve ecological and wildlife monitoring. </p><p>Based on this work, we’re excited to <a href="https://blog.google/technology/ai/partnerships-advanced-weather-climate-prediction/">partner with NOAA</a> on using AI and ML to amplify NOAA’s environmental monitoring, weather forecasting and climate research using Google Cloud’s infrastructure. </p><p><b>Accessibility</b><br />Machine learning continues to provide amazing opportunities for improving accessibility, because it can learn to transfer one kind of sensory input into others. As one example, we released <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.accessibility.reveal">Lookout</a>, an Android application that can help visually impaired users by identifying packaged foods, both in a grocery store and also in their kitchen cupboard at home. The <a href="http://ai.googleblog.com/2020/07/on-device-supermarket-product.html">machine learning system behind Lookout</a> demonstrates that a powerful-but-compact machine learning model can accomplish this in real-time on a phone for nearly 2 million products. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-An8rUAA2BM0/X_3ivtNUlRI/AAAAAAAAG9U/gbOvaNUnFzsaYggt8DZK3YrQwi6P3IIuACLcBGAsYHQ/s952/MustardWithPickles.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="400" src="https://1.bp.blogspot.com/-An8rUAA2BM0/X_3ivtNUlRI/AAAAAAAAG9U/gbOvaNUnFzsaYggt8DZK3YrQwi6P3IIuACLcBGAsYHQ/w199-h400/MustardWithPickles.gif" width="199" /></a></div><div style="text-align: center;"><br /></div><p>Similarly, people who communicate with sign language find it difficult to use video conferencing systems because even if they are signing, they are not detected as actively speaking by audio-based speaker detection systems. <a href="http://ai.googleblog.com/2020/10/developing-real-time-automatic-sign.html">Developing Real-Time, Automatic Sign Language Detection for Video Conferencing</a> presents a real-time sign language detection model and demonstrates how it can be used to provide video conferencing systems with a mechanism to identify the person signing as the active speaker. </p><p></p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-P1YGsUA97QY/X_3ZpVlhZRI/AAAAAAAAG74/D2cOTbWkU0cHffIxFCsnEZ__PlAceQ54ACLcBGAsYHQ/s400/image8.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="284" src="https://1.bp.blogspot.com/-P1YGsUA97QY/X_3ZpVlhZRI/AAAAAAAAG74/D2cOTbWkU0cHffIxFCsnEZ__PlAceQ54ACLcBGAsYHQ/w400-h284/image8.gif" width="400" /></a></div><p>We also enabled useful Android accessibility capabilities such as <a href="https://www.blog.google/outreach-initiatives/accessibility/voice-access-updates/">Voice Access</a> and <a href="https://www.blog.google/products/android/new-sound-notifications-on-android/">Sound Notifications</a> for important household sounds. </p><p></p><p><a href="https://ai.googleblog.com/2019/10/on-device-captioning-with-live-caption.html">Live Caption</a> was expanded to support calls on the Pixel phone with the ability to caption phone calls and video calls. This came out of the <a href="https://blog.google/outreach-initiatives/accessibility/live-relay-phone-calls-io/">Live Relay</a> research project, which enables <a href="https://www.linkedin.com/pulse/dad-its-first-time-we-have-ever-phoned-each-other-matthew-johnston/">deaf and hard of hearing people to make calls without assistance</a>. </p><p><b>Applications of ML to Other Fields</b><br />Machine learning continues to prove vital in helping us make progress across many fields of science. In 2020, in collaboration with the <a href="https://www.janelia.org/project-team/flyem">FlyEM</a> team at HHMI <a href="http://feeds.feedburner.com/blogspot/www.janelia.org">Janelia Research Campus</a>, we <a href="https://ai.googleblog.com/2020/01/releasing-drosophila-hemibrain.html">released the drosophila hemibrain connectome</a>, the large synapse-resolution map of brain connectivity, reconstructed using large-scale machine learning models applied to high-resolution electron microscope imaging of brain tissue. This connectome information will aid neuroscientists in a wide variety of inquiries, helping us all better understand how brains function. Be sure to check out the <a href="https://hemibrain-dot-neuroglancer-demo.appspot.com/#!gs://neuroglancer-janelia-flyem-hemibrain/v1.0/neuroglancer_demo_states/kc_apl_mpn1.json">very fly interactive 3-D UI</a>! </p><div class="separator" style="clear: both; text-align: center;"></div><p>The application of ML to problems in systems biology is also on the rise. Our <a href="https://research.google/teams/applied-science/gas/">Google Accelerated Science</a> team, in collaboration with our colleagues at Calico, have been <a href="http://ai.googleblog.com/2020/04/applying-machine-learning-toyeast.html">applying machine learning to yeast</a>, to get a better understanding of how genes work together as a whole system. We’ve also been exploring how to use <a href="https://research.google/pubs/pub49138/">model-based reinforcement learning in order to design biological sequences</a> like DNA or proteins that have desirable properties for medical or industrial uses. Model-based RL is used to improve sample efficiency. At each round of experimentation the policy is trained offline using a simulator fit on functional measurements from prior rounds. On various tasks like designing DNA transcription factor binding sites, designing antimicrobial proteins, and optimizing the energy of <a href="https://en.wikipedia.org/wiki/Ising_model">Ising models</a> based on protein structures, we find that model-based RL is an attractive alternative to existing methods. </p><p>In partnership with <a href="http://www.x-chemrx.com/">X-Chem Pharmaceuticals</a> and <a href="https://www.zebiai.com/">ZebiAI</a>, we have also been <a href="https://ai.googleblog.com/2020/06/unlocking-chemome-with-dna-encoded.html">developing ML techniques to do “virtual screening” of promising molecular compounds computationally</a>. Previous work in this area has tended to focus on relatively small sets of related compounds, but in this work, we are trying to use DNA-encoded small molecule libraries in order to be able to generalize to find “hits” across a wide swath of chemical space, reducing the need for slower, physical-based lab work in order to progress from idea to working pharmaceutical. </p><p>We’ve also seen success applying machine learning to core computer science and computer systems problems, a growing trend that is spawning entire new conferences like <a href="https://mlsys.org/">MLSys</a>. In <a href="https://research.google/pubs/pub49008/">Learning-based Memory Allocation for C++ Server Workloads</a>, a neural network-based language model predicts context-sensitive per-allocation site object lifetime information, and then uses this to organize the heap so as to reduce fragmentation. It is able to reduce fragmentation by up to 78% while only using huge pages (which are better for <a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer">TLB</a> behavior). <a href="https://ai.googleblog.com/2020/12/end-to-end-transferable-deep-rl-for.html">End-to-End, Transferable Deep RL for Graph Optimization</a> described an end-to-end transferable deep reinforcement learning method for computational graph optimization that shows 33%-60% speedup on three graph optimization tasks compared to <a href="https://www.tensorflow.org/">TensorFlow</a> default optimization, with 15x faster convergence over prior computation graph optimization methods. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-0BDxBbQHv7Q/X_3ewuPLRhI/AAAAAAAAG9A/GPwepypUdtUAwIbz4ggrxAhjBv6aSv8NwCLcBGAsYHQ/s1600/image3.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="160" src="https://1.bp.blogspot.com/-0BDxBbQHv7Q/X_3ewuPLRhI/AAAAAAAAG9A/GPwepypUdtUAwIbz4ggrxAhjBv6aSv8NwCLcBGAsYHQ/w640-h160/image3.gif" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Overview of GO: An end-to-end graph policy network that combines graph embedding and sequential attention.</td></tr></tbody></table><p>As described in <a href="http://ai.googleblog.com/2020/04/chip-design-with-deep-reinforcement.html">Chip Design with Deep Reinforcement Learning</a>, we have also been applying reinforcement learning to the problem of place-and-route in computer chip design. This is normally a very time-consuming, labor-intensive process, and is a major reason that going from an idea for a chip to actually having a fully designed and fabricated chip takes so long. Unlike prior methods, our approach has the ability to learn from past experience and improve over time. In particular, as we train over a greater number of chip blocks, our method becomes better at rapidly generating optimized placements for previously unseen chip blocks. The system is able to generate placements that usually outperform those of human chip design experts, and we have been using this system (running on TPUs) to do placement and layout for major portions of future generations of TPUs. <a href="http://ai.googleblog.com/2020/10/massively-large-scale-distributed.html">Menger</a> is a recent infrastructure we’ve built for large-scale distributed reinforcement learning that is yielding promising performance for difficult RL tasks such as chip design. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-yZGCjAHfebQ/X_3e54RCriI/AAAAAAAAG9E/lvtO0AQtEQU6NugLGVrqH0tswhYq4zhfACLcBGAsYHQ/s576/image22.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="200" src="https://1.bp.blogspot.com/-yZGCjAHfebQ/X_3e54RCriI/AAAAAAAAG9E/lvtO0AQtEQU6NugLGVrqH0tswhYq4zhfACLcBGAsYHQ/w400-h200/image22.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Macro placements of Ariane, an <a href="https://github.com/pulp-platform/ariane">open-source RISC-V</a> processor, as training progresses. On the left, the policy is being trained from scratch, and on the right, a pre-trained policy is being fine-tuned for this chip. Each rectangle represents an individual macro placement. Notice how the cavity that is occupied by non-macro logic cells that is discovered by the from-scratch policy is already present from the outset in the pre-trained policy’s placement.</td></tr></tbody></table><p><b>Responsible AI </b><br />The <a href="http://ai.google/principles">Google AI Principles</a> guide our development of advanced technologies. We continue to invest in <a href="https://research.google/pubs/?collection=responsible-ai">responsible AI research</a> and <a href="https://www.tensorflow.org/responsible_ai">tools</a>, update our <a href="https://ai.google/responsibilities/responsible-ai-practices/">recommended technical practices</a> in this area, and <a href="http://feeds.feedburner.com/blogspot/ai.google/responsibilities">share regular updates</a> — including a 2020 <a href="https://blog.google/technology/ai/update-work-ai-responsible-innovation/">blog post</a> and <a href="https://ai.google/static/documents/ai-principles-2020-progress-update.pdf">report</a> — on our progress in implementation.  </p><p>To help better understand the behavior of language models, we developed the <a href="https://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html">Language Interpretability Tool (LIT)</a>, a toolkit for better interpretability of language models, enabling interactive exploration and analysis of their decisions. We developed techniques for <a href="https://ai.googleblog.com/2020/10/measuring-gendered-correlations-in-pre.html">measuring gendered correlations in pre-trained language models</a> and <a href="https://ai.googleblog.com/2020/04/a-scalable-approach-to-reducing-gender.html">scalable techniques for reducing gender bias in Google Translate. </a>We used the kernel trick <a href="https://arxiv.org/pdf/2002.08484.pdf">to propose a simple method to estimate the influence of a training data example on an individual prediction</a>. To help non-specialists interpret machine learning results, we extended the <a href="https://blog.google/technology/developers/io19-helpful-google-everyone/">TCAV technique</a> introduced in 2019 to now provide a <a href="https://arxiv.org/abs/1910.07969">complete and sufficient set of concepts</a>. With the original TCAV work, we were able to say that ‘fur’ and ‘long ears’ are important concepts for ‘rabbit’ prediction. With this work, we can also say that these two concepts are enough to fully explain the prediction; you don’t need any other concepts. <a href="https://arxiv.org/abs/2007.04612">Concept bottleneck models</a> are a technique to make models more interpretable by training them so that one of the layers is aligned with pre-defined expert concepts (e.g., “bone spurs present”, or “wing color”, as shown below) before making a final prediction for a task, so that we can not only interpret but also turn on/off these concepts on the fly. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-YUBHmYguWnI/X_3azbXjbUI/AAAAAAAAG8E/_W0-RYdLnFc2majx2sdSANYwR5r5tRDNgCLcBGAsYHQ/s984/image29.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="333" src="https://1.bp.blogspot.com/-YUBHmYguWnI/X_3azbXjbUI/AAAAAAAAG8E/_W0-RYdLnFc2majx2sdSANYwR5r5tRDNgCLcBGAsYHQ/w400-h333/image29.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Aligning predictions to pre-identified concepts can make models more interpretable, as described in <a href="https://arxiv.org/abs/2007.04612">Concept Bottleneck Models.</a></td></tr></tbody></table><p>In collaboration with many other institutions, we also looked into <a href="https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html">memorization effects of language models</a>, showing that training data extraction attacks are realistic threats on state-of-the-art large language models. This finding along with a result that <a href="https://arxiv.org/pdf/2004.00053.pdf">embedding models can leak information</a> can have significant privacy implications (especially for models trained on private data). In <a href="https://research.google/pubs/pub49091/">Thieves of Sesame Street: Model Extraction on BERT-based APIs</a>, we demonstrated that attackers with only API access to a language model could create models whose outputs had very high correlation with the original model, even with relatively few API queries to the original model. Subsequent work demonstrated that attackers can <a href="https://arxiv.org/abs/2003.04884">extract smaller models with arbitrary accuracy</a>. On the AI Principle of safety we demonstrated that thirteen published <a href="https://proceedings.neurips.cc/paper/2020/file/11f38f8ecd71867b42433548d1078e38-Paper.pdf">defenses to adversarial examples can be circumvented</a> despite attempting to perform evaluations using adaptive attacks. Our work focuses on laying out the methodology and the approach necessary to perform an adaptive attack, and thus will allow the community to make further progress in building more robust models. </p><p>Examining the way in which machine learning systems themselves are examined is also an important area of exploration. In collaboration with the <a href="https://www.partnershiponai.org/">Partnership on AI</a>, we defined a <a href="https://arxiv.org/abs/2001.00973">framework for how to audit the use of machine learning in software product settings</a>, drawing on lessons from the aerospace, medical devices, and finance industries and their best practices. In joint work with University of Toronto and MIT, we identified <a href="https://arxiv.org/abs/2001.00964">several ethical concerns that can arise when auditing the performance of facial recognition systems</a>. In joint work with the University of Washington, we identified some <a href="https://arxiv.org/abs/2002.03256">important considerations related to diversity and inclusion when choosing subsets </a>for evaluating algorithmic fairness. As an initial step in making responsible AI work for the next billion users and to help understand if notions of fairness were consistent in different parts of the world, we analyzed and created a <a href="https://arxiv.org/abs/2012.03659">framework for algorithmic fairness in India</a>, accounting for datasets, fairness optimizations, infrastructures, and ecosystems </p><p>The <a href="https://arxiv.org/abs/1810.03993">Model Cards</a> work that was introduced in collaboration with the University of Toronto in 2019 has been growing in influence.  Indeed, many well-known models like OpenAI’s <a href="https://github.com/openai/gpt-2/blob/master/model_card.md">GPT-2</a> and <a href="https://github.com/openai/gpt-3/blob/master/model-card.md">GPT-3</a>, many of Google’s <a href="https://google.github.io/mediapipe/solutions/models.html">MediaPipe models</a> and various <a href="https://modelcards.withgoogle.com/about">Google Cloud APIs</a> have all adopted Model Cards as a way of giving users of a machine learning model more information about the model’s development and the observed behavior of the model under different conditions. To make this easier for others to adopt for their own machine learning models, we also introduced the <a href="https://ai.googleblog.com/2020/07/introducing-model-card-toolkit-for.html">Model Card Toolkit</a> for easier model transparency reporting. In order to increase transparency in ML development practices, we demonstrate the applicability of a range of <a href="https://arxiv.org/abs/2010.13561">best practices throughout the dataset development lifecycle</a>, including data requirements specification and data acceptance testing.  </p><p>In collaboration with the U.S. National Science Foundation (NSF), we <a href="https://blog.google/technology/ai/partnering-nsf-human-ai-collaboration/">announced and helped to fund a National AI Research Institute for Human-AI Interaction and Collaboration</a>. We also released the <a href="https://arxiv.org/pdf/1910.11779.pdf">MinDiff framework</a>, a new regularization technique available in the <a href="https://tensorflow.org/responsible_ai/model_remediation/">TF Model Remediation library</a> for effectively and efficiently mitigating unfair biases when training ML models, along with <a href="https://ai.googleblog.com/2020/02/ml-fairness-gym-tool-for-exploring-long.html">ML-fairness gym</a> for building simple simulations that explore potential long-run impacts of deploying machine learning-based decision systems in social environments.  </p><p>In addition to developing frameworks for fairness, we developed approaches for identifying and improving the health and quality of experiences with Recommender Systems, including using <a href="https://www.ashudeepsingh.com/publications/facctrec2020_singh_et_al.pdf">reinforcement learning to introduce safer trajectories</a>. We also continue to work on improving the reliability of our machine learning systems, where we’ve seen that approaches such as <a href="https://arxiv.org/abs/2010.02338">generating adversarial examples</a> can improve robustness and that <a href="https://proceedings.neurips.cc/paper/2020/file/07fc15c9d169ee48573edd749d25945d-Paper.pdf">robustness approaches can improve fairness</a>. </p><p><a href="https://en.wikipedia.org/wiki/Differential_privacy">Differential privacy</a> is a way to formally quantify privacy protections and requires a rethinking of the most basic algorithms to operate in a way that they do not leak information about any particular individual. In particular, differential privacy can help in addressing memorization effects and information leakage of the kinds mentioned above. In 2020 there were a number of exciting developments, from more efficient ways of computing private <a href="https://papers.nips.cc/paper/2020/file/a0dc078ca0d99b5ebb465a9f1cad54ba-Paper.pdf">empirical risk minimizers</a> to <a href="https://papers.nips.cc/paper/2020/file/299dc35e747eb77177d9cea10a802da2-Paper.pdf">private clustering methods</a> with tight approximation guarantees and <a href="https://papers.nips.cc/paper/2020/file/e3019767b1b23f82883c9850356b71d6-Paper.pdf">private sketching algorithms</a>. We also <a href="https://opensource.googleblog.com/2020/06/expanding-our-differential-privacy.html">open sourced the differential privacy libraries</a> that lie at the core of our internal tools, taking <a href="https://github.com/google/differential-privacy/blob/main/common_docs/Secure_Noise_Generation.pdf">extra care</a> to protect against leakage caused by the floating point representation of real numbers. These are the exact same tools that we use to produce differentially private <a href="https://www.google.com/covid19/mobility/">COVID-19 mobility reports</a> that have been a valuable source of anonymous data for researchers and policymakers.  </p><p>To help developers assess the privacy properties of their classification models we released an <a href="https://blog.tensorflow.org/2020/06/introducing-new-privacy-testing-library.html">ML privacy testing library in Tensorflow</a>. We hope this library will be the starting point of a robust privacy testing suite that can be used by any machine learning developer around the world. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-WXjcaxazDVo/X_3bBn7styI/AAAAAAAAG8I/Ucywc6Q5u9QkjoKXmqnIhaTm2G-Hs6M8wCLcBGAsYHQ/s608/image16.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="399" src="https://1.bp.blogspot.com/-WXjcaxazDVo/X_3bBn7styI/AAAAAAAAG8I/Ucywc6Q5u9QkjoKXmqnIhaTm2G-Hs6M8wCLcBGAsYHQ/w400-h399/image16.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Membership inference attack on models for <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a>. The x-axis is the test accuracy of the model, and y-axis is vulnerability score (lower means more private). Vulnerability grows while test accuracy remains the same — better generalization could prevent privacy leakage.</td></tr></tbody></table><p>In addition to pushing the state of the art in developing private algorithms, I am excited about the advances we made in weaving privacy into the fabric of our products. One of the best examples is Chrome’s <a href="https://web.dev/digging-into-the-privacy-sandbox/">Privacy Sandbox</a>, which changes the underpinnings of the advertising ecosystem and helps systematically protect individuals’ privacy. As part of the project, we proposed and <a href="https://github.com/google/ads-privacy/blob/master/proposals/FLoC/FLOC-Whitepaper-Google.pdf">evaluated</a> a number of different APIs, including federated learning of cohorts (<a href="https://github.com/WICG/floc">FLoC</a>) for interest based targeting, and aggregate APIs for differentially <a href="https://github.com/WICG/conversion-measurement-api/blob/master/SERVICE.md">private measurement</a>.  </p><p>Launched in 2017, <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">federated learning</a> is now a complete research field unto itself, with over <a href="https://scholar.google.com/scholar?q=%2B%22federated+learning%22+-%22e-learning%22+-education&amp;hl=en&amp;as_sdt=1%2C48&amp;as_vis=1&amp;as_ylo=2020&amp;as_yhi=2020">3000 publications</a> on federated learning appearing in 2020 alone. Our cross-institutional <a href="https://arxiv.org/abs/1912.04977">Advances and Open Problems in Federated Learning</a> survey paper published in 2019 has been cited <a href="https://scholar.google.com/scholar?cites=17946402925615366826&amp;as_sdt=5,48&amp;sciodt=0,48&amp;hl=en">367 times</a> in the past year, and an updated version will soon <a href="https://www.nowpublishers.com/article/Details/MAL-083">be published</a> in the Foundations &amp; Trends in Machine Learning series. In July, we hosted a Workshop on Federated Learning and Analytics, and made <a href="https://www.youtube.com/playlist?list=PLSIUOFhnxEiCJS8q6SYdc0944xlV_6Jbu">all research talks</a> and a <a href="https://www.youtube.com/watch?v=JBNas6Yd30A">TensorFlow Federated tutorial</a> publicly available. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-_zB8eZKtpSc/X_3bJrmES3I/AAAAAAAAG8M/fKK0lI2d-HwFOdCIcUwcMgY_gtWUg0nlwCLcBGAsYHQ/s1015/image15.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="302" src="https://1.bp.blogspot.com/-_zB8eZKtpSc/X_3bJrmES3I/AAAAAAAAG8M/fKK0lI2d-HwFOdCIcUwcMgY_gtWUg0nlwCLcBGAsYHQ/w640-h302/image15.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The lifecycle of an FL-trained model and the various actors in a federated learning system.</td></tr></tbody></table><p>We continue to push the state of the art in federated learning, including the development of new federated optimization algorithms including <a href="https://arxiv.org/abs/2003.00295">adaptive learning algorithms</a>, <a href="https://arxiv.org/abs/2010.05273">posterior averaging algorithms</a>, and <a href="https://arxiv.org/abs/2008.03606">techniques for mimicking centralized algorithms in federated settings</a>, substantial improvements in complimentary <a href="https://eprint.iacr.org/2020/704">cryptographic protocols</a>, and more. We announced and deployed <a href="https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html">federated analytics</a>, enabling data science over raw data that is stored locally on users’ devices. New uses of federated learning in Google products include <a href="https://security.googleblog.com/2020/10/privacy-preserving-smart-input-with.html">contextual emoji suggestions</a> in Gboard, and pioneering privacy-preserving medical research with <a href="https://blog.google/technology/health/google-health-studies-app/">Google Health Studies</a>. Furthermore, in <a href="https://proceedings.neurips.cc//paper/2020/file/313f422ac583444ba6045cd122653b0e-Paper.pdf">Privacy Amplification via Random Check-Ins</a> we presented the first privacy accounting mechanism for Federated Learning. </p><p>Security for our users is also an area of considerable interest for us. In 2020, we continued to improve protections for Gmail users, by deploying a <a href="https://security.googleblog.com/2020/02/improving-malicious-document-detection.html">new ML-based document scanner</a> that provides protection against malicious documents, which increased malicious office document detection by 10% on a daily basis. Thanks to its ability to generalize, this tool has been very effective at blocking some adversarial malware campaigns that elude other detection mechanisms and increased our detection rate by 150% in some cases.  </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-vrb82SspPTg/X_3bSLSPYpI/AAAAAAAAG8U/riT10Ea4OGY-aBMTihg5QTP8yQw3UuuuQCLcBGAsYHQ/s640/image4.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="250" src="https://1.bp.blogspot.com/-vrb82SspPTg/X_3bSLSPYpI/AAAAAAAAG8U/riT10Ea4OGY-aBMTihg5QTP8yQw3UuuuQCLcBGAsYHQ/w640-h250/image4.png" width="640" /></a></div><p>On the account protection side, we released <a href="https://security.googleblog.com/2020/01/say-hello-to-opensk-fully-open-source.html">a fully open-source security key firmware </a>to help advance state of art in the two factor authentication space, staying focused on security keys as the best way to protect accounts against phishing.  </p><p><b>Natural Language Understanding</b><br />Better understanding of language is an area where we saw considerable progress this year. Much of the work in this space from Google and elsewhere now relies on <a href="https://arxiv.org/abs/1706.03762">Transformers</a>, a particular style of neural network model <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">originally developed for language problems</a> (but with a growing body of evidence that they are also useful for <a href="https://ai.googleblog.com/2020/12/transformers-for-image-recognition-at.html">images</a>, <a href="https://arxiv.org/abs/1906.02634">videos</a>, <a href="https://arxiv.org/abs/2005.08100">speech</a>, <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">protein folding</a>, and a wide variety of other domains).  </p><p>One area of excitement is in dialog systems that can chat with a user about something of interest, often encompassing multiple turns of interaction. While successful work in this area to date has involved creating systems that are specialized around particular topics (e.g., <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex</a>) these systems cannot carry on general conversations. In pursuit of the general research goal of creating systems capable of much more open-ended dialog, in 2020 we described <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html">Meena</a>, a learned conversational agent that aspirationally can chat about anything. Meena achieves high scores on a dialog system metric called SSA, which measures both sensibility and specificity of responses. We’ve seen that as we scale up the model size of Meena, it is able to achieve lower perplexity and, as shown in the <a href="https://arxiv.org/abs/2001.09977">paper</a>, lower perplexity correlates extremely closely with improved SSA. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-RwuXFPIhWFg/X_3cMMBijtI/AAAAAAAAG8k/XglGPXwHtxMXmmvVbCnYZywxWx5Mj1h2gCLcBGAsYHQ/s728/image26.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://1.bp.blogspot.com/-RwuXFPIhWFg/X_3cMMBijtI/AAAAAAAAG8k/XglGPXwHtxMXmmvVbCnYZywxWx5Mj1h2gCLcBGAsYHQ/w369-h400/image26.gif" width="369" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">A chat between Meena (<b>left</b>) and a person (<b>right</b>).</td></tr></tbody></table><p>One well-known issue with generative language models and dialog systems is that when discussing factual data, the model’s capacity may not be large enough to remember every specific detail about a topic, so they generate language that is plausible but incorrect. (This is not unique to machines — people can commit these errors too.) To address this in dialog systems, we are exploring ways to augment a conversational agent by giving it access to external information sources (e.g., a large corpus of documents or a search engine API), and developing learning techniques to use this as an additional resource in order to generate language that is consistent with the retrieved text. Work in this area includes <a href="http://ai.googleblog.com/2020/08/realm-integrating-retrieval-into.html">integrating retrieval into language representation models</a> (and a key underlying technology for this to work well is something like <a href="https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html">ScaNN, an efficient vector similarity search</a>, to efficiently match the desired information to information in the corpus of text). Once appropriate content is found, it can be better understood with approaches like <a href="http://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html">using neural networks to find answers in table</a><span style="text-decoration: underline;">s</span> and <a href="http://ai.googleblog.com/2020/06/extracting-structured-data-from.html">extracting structured data from templatic documents</a>. Our work on <a href="http://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html">PEGASUS, a state-of-the-art model for abstractive text summarization</a> can also help to create automatic summaries from any piece of text, a general technique useful in conversations, retrieval systems, and many other places. </p><p>Efficiency of NLP models has also been a significant focus for our work in 2020. Techniques like transfer learning and multi-task learning can dramatically help with making general NLP models usable for new tasks with modest amounts of computation. Work in this vein includes <a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html">transfer learning explorations in T5</a>, sparse activation of models (as in our <a href="https://arxiv.org/abs/2006.16668">GShard work</a> mentioned below), and <a href="https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html">more efficient model pre-training with ELECTRA</a>. Several threads of work also look to improve on the basic Transformer architecture, including <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">Reformer</a>, which uses locality-sensitive hashing and reversible computation to more efficiently support much larger attention windows, <a href="https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html">Performers</a>, which use an approach for attention that scales linearly rather than quadratically (and discusses its use in the context of protein modeling), and <a href="https://arxiv.org/abs/2004.08483">ETC</a> and <a href="https://arxiv.org/abs/2007.14062">BigBird</a>, which utilize global and sparse random connections, to enable linear scaling for larger and structured sequences. We also explored techniques for <a href="http://ai.googleblog.com/2020/09/advancing-nlp-with-efficient-projection.html">creating very lightweight NLP models</a> that are 100x smaller than a larger BERT model, but perform nearly as well for some tasks, making them very suitable for on-device NLP. In <a href="https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html">Encode, Tag and Realize</a>, we also explored new approaches for generative text models that use edit operations rather than fully general text generation, which can have advantages in computation requirements for generation, more control over the generated text, and require less training data. </p><p><b>Language Translation</b><br />Effective language translation helps bring the world closer together by enabling us to all communicate, despite speaking different languages. To date, over a billion people around the world use Google Translate, and last year we added support for <a href="https://blog.google/products/translate/five-new-languages/">five new languages</a> (Kinyarwanda, Odia, Tatar, Turkmen and Uyghur, collectively spoken by 75 million people). <a href="https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html">Translation quality continues to improve</a>, showing an average +5 <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> point gain across more than 100 languages from May 2019 to May 2020, through a wide variety of techniques like improved model architectures and training, better handling of noise in datasets, multilingual transfer and multi-task learning, and better use of monolingual data to improve low-resource languages (those without much written public content on the web), directly in line with our goals of improving ML fairness of machine learning systems to provide benefits to the greatest number of people possible. </p><p>We strongly believe that continued scaling of multilingual translation models will bring further quality improvements, especially to the billions of speakers of low-resource languages around the world. In <a href="https://arxiv.org/abs/2006.16668">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a>, Google researchers showed that training sparsely-activated multilingual translation models of up to 600 billion parameters leads to major improvements in translation quality for 100 languages as measured by BLEU score improvement over a baseline of a separate 400M parameter monolingual baseline model for each language. Three trends stood out in this work, illustrated by Figure 6 in the paper, reproduced below (see the paper for complete discussion):  </p><ul><li>The BLEU score improvements from multilingual training are high for all languages but are even higher for low-resource languages (right hand side of graph is higher than the left) whose speakers represent billions of people in some of the world’s most marginalized communities. Each rectangle on the figure represents languages with 1B speakers. </li><li>The larger and deeper the model, the larger the BLEU score improvements were across all languages (the lines hardly ever cross). </li><li>Large, sparse models also show a ~10x to 100x improvement in computational efficiency for model training over training a large, dense model, while simultaneously matching or significantly exceeding the BLEU scores of the large, dense model (computational efficiency discussed in paper). </li></ul><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-kAM6xOWOo1s/X_3culAiInI/AAAAAAAAG8s/XBKrq1xs4rIlpJ23ZZ40U5Bvw-mpZ-wJgCLcBGAsYHQ/s1999/image24.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="272" src="https://1.bp.blogspot.com/-kAM6xOWOo1s/X_3culAiInI/AAAAAAAAG8s/XBKrq1xs4rIlpJ23ZZ40U5Bvw-mpZ-wJgCLcBGAsYHQ/w640-h272/image24.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">An illustration of the significant gains in translation quality across 100 languages for large, sparsely-activated language models described in <a href="https://arxiv.org/abs/2006.16668">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a>.</td></tr></tbody></table><p>We’re actively working on bringing the benefits demonstrated in this GShard research work to Google Translate, as well as training single models that cover 1000 languages, including languages like Dhivehi and Sudanese Arabic (while sharing <a href="https://arxiv.org/abs/2010.14571">some challenges that needed solving</a> along the way). </p><p>We also developed techniques to create <a href="https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html">language-agnostic representations of sentences for BERT models</a>, which can help with developing better translation models. To more effectively evaluate translation quality, we introduced <a href="https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html">BLEURT, a new metric for evaluating language generation</a> for tasks like translation that considers the semantics of the generated text, rather than just the amount of word overlap with ground-truth data, illustrated in the table below. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Wi3AJqnT84A/X_3dNzYgHnI/AAAAAAAAG80/GHJdudNI14Mnxv4OgLUl0I_sHLE1OpOxwCLcBGAsYHQ/s1189/BLEURT.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="122" src="https://1.bp.blogspot.com/-Wi3AJqnT84A/X_3dNzYgHnI/AAAAAAAAG80/GHJdudNI14Mnxv4OgLUl0I_sHLE1OpOxwCLcBGAsYHQ/w640-h122/BLEURT.png" width="640" /></a></div><p><b>Machine Learning Algorithms</b><br />We continue to develop new machine learning algorithms and approaches for training that enable systems to learn more quickly and from less supervised data. By <a href="https://ai.googleblog.com/2020/05/speeding-up-neural-network-training.html">replaying intermediate results during training of neural networks</a>, we find that we can fill idle time on ML accelerators and therefore can train neural networks faster. By <a href="https://ai.googleblog.com/2020/09/improving-sparse-training-with-rigl.html">changing the connectivity of neurons dynamically during training</a>, we can find better solutions compared with statically-connected neural networks. We also developed <a href="http://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html">SimCLR</a>, a new self-supervised and semi-supervised learning technique that simultaneously maximizes agreement between differently transformed views of the same image and minimizes agreement between transformed views of different images. This approach significantly improves on the best self-supervised learning techniques. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-_tD7oYvK2A8/X_3jwySDTuI/AAAAAAAAG9c/b04w3HVZhDAOvmyLlwV17gwOxROdqzLVwCLcBGAsYHQ/s584/image19.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="276" src="https://1.bp.blogspot.com/-_tD7oYvK2A8/X_3jwySDTuI/AAAAAAAAG9c/b04w3HVZhDAOvmyLlwV17gwOxROdqzLVwCLcBGAsYHQ/w400-h276/image19.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><a href="http://www.image-net.org/">ImageNet</a> top-1 accuracy of linear classifiers trained on representations learned with different self-supervised methods (pretrained on ImageNet). Gray cross indicates supervised <a href="https://arxiv.org/abs/1512.03385">ResNet-50</a>.</td></tr></tbody></table><p>We also extended the idea of <a href="https://arxiv.org/abs/2004.11362">contrastive learning to the supervised regime</a>, resulting in a loss function that significantly improves over cross-entropy for supervised classification problems. </p><p><b>Reinforcement Learning</b><br />Reinforcement learning (RL), which learns to make good long-term decisions from limited experience, has been an important focus area for us. An important challenge in RL is to learn to make decisions from few data points, and we’ve improved RL algorithm efficiency through learning from fixed datasets, learning from other agents, and improving exploration.  </p><p>A major focus area this year has been around <em>offline </em>RL, which <em>relies solely on fixed</em>, <em>previously collected datasets</em> (for example, from previous experiments or human demonstrations), extending RL to the applications that can’t collect training data on-the-fly. We’ve <a href="https://ai.googleblog.com/2020/07/duality-new-approach-to-reinforcement.html">introduced a duality approach to RL</a>, developed improved algorithms for <a href="https://ai.googleblog.com/2020/04/off-policy-estimation-for-infinite.html">off-policy evaluation</a>, estimating <a href="https://arxiv.org/abs/2010.11652">confidence</a> <a href="https://arxiv.org/abs/2007.13609">intervals</a>, and <a href="https://arxiv.org/abs/2006.04779">offline policy optimization</a>. In addition, we’re collaborating with the broader community to tackle these problems by releasing <a href="https://ai.googleblog.com/2020/08/tackling-open-challenges-in-offline.html">open-source benchmark datasets</a>, and <a href="https://ai.googleblog.com/2020/04/an-optimistic-perspective-on-offline.html">DQN dataset for Atari</a>.  </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-vSYc14elrPo/X_3kXyLZl_I/AAAAAAAAG9o/FGTb9PBbtEYbFx3BM5mJz2bBrDmvSA4cQCLcBGAsYHQ/s1600/image32.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="240" src="https://1.bp.blogspot.com/-vSYc14elrPo/X_3kXyLZl_I/AAAAAAAAG9o/FGTb9PBbtEYbFx3BM5mJz2bBrDmvSA4cQCLcBGAsYHQ/w640-h240/image32.gif" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Offline RL on Atari games using the DQN Replay Dataset.</td></tr></tbody></table><p>Another line of research improved sample efficiency by learning from other agents through apprenticeship learning. We developed methods to learn from <a href="https://arxiv.org/abs/1907.08027">informed agents</a>, <a href="https://arxiv.org/abs/2006.04678">matching other agent’s distribution</a>, or learning from <a href="http://www.ifaamas.org/Proceedings/aamas2020/pdfs/p548.pdf">adversarial examples</a>. To improve the exploration in RL, we explored <a href="https://research.google/pubs/pub48868/">bonus-based exploration</a> methods including imitation techniques able to <a href="https://arxiv.org/abs/2006.12917">mimic structured exploration</a> arising in agents having prior knowledge about their environment.  </p><p>We’ve also made significant advances in the mathematical theory of reinforcement learning. One of our main areas of research was studying reinforcement learning as an optimization process. We found connections to the <a href="https://arxiv.org/abs/1906.09784">Frank-Wolfe algorithm</a>, <a href="https://arxiv.org/abs/1910.09322">momentum</a> methods, <a href="https://arxiv.org/abs/1910.09322">KL divergence regularization</a>, <a href="https://arxiv.org/abs/2006.11266">operator theory</a>, and <a href="https://arxiv.org/abs/2005.06392">convergence analysis</a>; some of these insights led to an <a href="https://arxiv.org/abs/2007.14430">algorithm that achieves state-of-the-art performance</a> in challenging RL benchmarks and <a href="https://proceedings.neurips.cc/paper/2020/file/f1cf2a082126bf02de0b307778ce73a7-Paper.pdf">discovery that polynomial transfer functions</a> avoid convergence problems associated with softmax, both in RL and supervised learning. We’ve made some exciting progress on the topic of safe reinforcement learning, where one seeks to discover optimal control rules while respecting important experimental constraints. This includes a <a href="https://corlconf.github.io/paper_171/">framework for safe policy optimization</a>. We studied <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6203">efficient RL-based algorithms</a> for solving a class of problems known as mean field games, which model systems with a large number of decision-makers, from mobile networks to electric grids. </p><p>We’ve made breakthroughs toward generalization to new tasks and environments, an important challenge for scaling up RL to complex real-world problems. A 2020 focus area was population-based learning-to-learn methods, where another RL or evolutionary agent trained a population of RL agents to create a curriculum of <a href="https://proceedings.neurips.cc/paper/2020/file/985e9a46e10005356bbaf194249f6856-Paper.pdf">emergent complexity</a>, and discover <a href="https://drive.google.com/file/d/1KTuibxpaM6NzgqzYPHmchLqsUusjHqeX/view">new state-of-the-art RL algorithms</a>. Learning to <a href="https://ai.googleblog.com/2020/10/estimating-impact-of-training-data-with.html">estimate the importance of data points</a> in the training set and <a href="http://ai.googleblog.com/2020/06/using-selective-attention-in.html">parts of visual input</a> with selective attention resulted in significantly more skillful RL agents.  </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-V1VIJ7p5Wlk/X_3kkThuRaI/AAAAAAAAG9s/YorQr0nyQGU-dkwzQiJALUs4ga7087E8gCLcBGAsYHQ/s816/image7.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="640" src="https://1.bp.blogspot.com/-V1VIJ7p5Wlk/X_3kkThuRaI/AAAAAAAAG9s/YorQr0nyQGU-dkwzQiJALUs4ga7087E8gCLcBGAsYHQ/w368-h640/image7.png" width="368" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Overview of our method and illustration of data processing flow in AttentionAgent. <b>Top:</b> Input transformation — A sliding window segments an input image into smaller patches, and then “flattens” them for future processing. <b>Middle:</b> Patch election — The modified self-attention module holds votes between patches to generate a patch importance vector. <b>Bottom:</b> Action generation — AttentionAgent picks the patches of the highest importance, extracts corresponding features and makes decisions based on them.</td></tr></tbody></table><p>Further, we made progress in model-based RL by showing that learning predictive behavior models <a href="https://arxiv.org/abs/2007.12401">accelerates RL learning</a>, and enables <a href="https://corlconf.github.io/paper_151/">decentralized cooperative</a> multi-agent tasks in diverse teams, and learning <a href="http://ai.googleblog.com/2020/03/introducing-dreamer-scalable.html">long-term behavior models</a>. Observing that skills bring predictable changes in the environment, we discover<a href="http://ai.googleblog.com/2020/05/dads-unsupervised-reinforcement.html"> skills without supervision</a>. Better representations <a href="https://arxiv.org/abs/2007.05520">stabilize RL learning</a>, while <a href="http://proceedings.mlr.press/v97/gelada19a/gelada19a.pdf">hierarchical latent spaces</a> and <a href="https://arxiv.org/abs/2006.02243">value-improvement paths</a> yield better performance.  </p><p>We shared open source tools for scaling up and productionizing RL. To expand the scope and problems tackled by users, we’ve introduced <a href="http://ai.googleblog.com/2020/03/massively-scaling-reinforcement.html">SEED</a>, a massively parallel RL agent, released a library for <a href="https://github.com/google-research/rl-reliability-metrics">measuring the RL algorithm reliability</a>, and a new version of <a href="https://github.com/tensorflow/agents">TF-Agents</a> that includes distributed RL, TPU support, and a full set of <a href="https://github.com/tensorflow/agents/tree/master/tf_agents/bandits">bandit</a> algorithms. In addition, we performed a <a href="https://arxiv.org/abs/2006.05990">large empirical study</a> of RL algorithms to improve hyperparameter selection and algorithm design. </p><p>Finally, in collaboration with Loon, we <a href="https://www.nature.com/articles/s41586-020-2939-8">trained and deployed RL to more efficiently control stratospheric balloons</a>, improving both power usage and their ability to navigate.  </p><p><b>AutoML</b><br />Using learning algorithms to develop new machine learning techniques and solutions, or meta-learning, is a very active and exciting area of research. In much of our previous work in this area, we’ve created search spaces that look at how to find ways to combine sophisticated hand-designed components together in interesting ways. In <a href="http://ai.googleblog.com/2020/07/automl-zero-evolving-code-that-learns.html">AutoML-Zero: Evolving Code that Learns</a>, we took a different approach, by giving an evolutionary algorithm a search space consisting of very primitive operations (like addition, subtraction, variable assignment, and matrix multiplication) in order to see if it was possible to evolve modern ML algorithms from scratch. The presence of useful learning algorithms in this space is incredibly sparse, so it is remarkable that the system was able to progressively evolve more and more sophisticated ML algorithms. As shown in the figure below, the system reinvents many of the most important ML discoveries over the past 30 years, such as linear models, gradient descent, rectified linear units, effective learning rate settings and weight initializations, and gradient normalization. </p><div style="text-align: center;"><a href="https://1.bp.blogspot.com/-IXGxCFUaSXw/X_3lPXvmZbI/AAAAAAAAG94/bevBHEzS07wviLYzBQph6P6V5N_-yV-qQCLcBGAsYHQ/s1600/image9.png"><img border="0" height="381" src="https://1.bp.blogspot.com/-IXGxCFUaSXw/X_3lPXvmZbI/AAAAAAAAG94/bevBHEzS07wviLYzBQph6P6V5N_-yV-qQCLcBGAsYHQ/w640-h381/image9.png" width="640" /></a></div><p>We also used meta-learning to discover a variety of new efficient architectures for object detection in both still images and videos.  Last year’s work on <a href="https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html">EfficientNet</a> for efficient image classification architectures showed significant accuracy improvements and computational cost reductions for image classification. In follow-on work this year, <a href="http://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html">EfficientDet: Towards Scalable and Efficient Object Detection</a> builds on top of the EfficientNet work to derive new efficient architectures for object detection and localization, showing remarkable improvements in both highest absolute accuracy, as well as computational cost reductions of 13-42x over previous approaches to achieve a given level of accuracy. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-UJHpTxtgpa4/X_3lWBIb94I/AAAAAAAAG98/gy9ygEBEOeYToDkdXyw2iGDSpgf_LTuTACLcBGAsYHQ/s792/image28.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="291" src="https://1.bp.blogspot.com/-UJHpTxtgpa4/X_3lWBIb94I/AAAAAAAAG98/gy9ygEBEOeYToDkdXyw2iGDSpgf_LTuTACLcBGAsYHQ/w400-h291/image28.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">EfficientDet achieves state-of-the-art 52.2 mAP, up 1.5 points from the prior state of the art (not shown since it is at 3045B FLOPs) on COCO test-dev under the same setting. Under the same accuracy constraint, EfficientDet models are 4x-9x smaller and use 13x-42x less computation than previous detectors.</td></tr></tbody></table><p>Our work on <a href="https://ai.googleblog.com/2020/06/spinenet-novel-architecture-for-object.html">SpineNet</a> describes a meta-learned architecture that can retain spatial information more effectively, allowing detection to be done at finer resolution. We also focused on learning effective architectures for a variety of video classification problems. <a href="https://research.google/pubs/pub48795/">AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures</a>, <a href="https://arxiv.org/abs/2008.08072">AssembleNet++: Assembling Modality Representations via Attention Connections</a>, and <a href="https://arxiv.org/abs/2007.12034">AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification</a> demonstrate how to use evolutionary algorithms to create novel state-of-the-art video processing machine learning architectures. </p><p>This approach can also be used to develop effective model architectures for time series forecasting. <a href="http://ai.googleblog.com/2020/12/using-automl-for-time-series-forecasting.html">Using AutoML for Time Series Forecasting</a> describes the system that discovers new forecasting models via an automated search over a search space involving many interesting kinds of low-level building blocks, and its effectiveness was demonstrated in the Kaggle <a href="https://mofc.unic.ac.cy/m5-competition/">M5 Forecasting Competition</a>, by generating an algorithm and system that placed 138th out of 5558 participants (top 2.5%). While many of the competitive forecasting models required months of manual effort to create, our AutoML solution found the model in a short time with only a moderate compute cost (500 CPUs for 2 hours) and no human intervention. </p><p><b>Better Understanding of ML Algorithms and Models</b><br />Deeper understanding of machine learning algorithms and models is crucial for designing and training more effective models, as well as understanding when models may fail. Last year, we focused on fundamental questions around representation power, optimization, model generalization, and label noise, among others. As mentioned earlier in this post, <a href="https://arxiv.org/abs/1706.03762">Transformer networks</a> have had a huge impact on modeling language, speech and vision problems, but what is the class of functions represented by these models? Recently we showed that <a href="https://research.google/pubs/pub48959/">transformers are universal approximators for sequence-to-sequence functions</a>. Furthermore, <a href="https://arxiv.org/abs/2006.04862">sparse transformers also remain universal approximators</a> even when they use just a linear number of interactions among the tokens. We have been developing new optimization techniques based on layerwise adaptive learning rates to improve the convergence speed of transformers, e.g., <a href="https://arxiv.org/abs/1904.00962">Large batch optimization for deep learning (LAMB): Training BERT in 76 minutes</a>.  </p><p>As neural networks are made wider and deeper, they often train faster and generalize better. This is a core mystery in deep learning since classical learning theory suggests that large networks should overfit more. We are working to understand neural networks in this overparameterized regime. In the limit of <em>infinite</em> width, neural networks take on a surprisingly simple form, and are described by a Neural Network Gaussian Process (NNGP) or Neural Tangent Kernel (NTK). We studied this phenomenon <a href="http://proceedings.mlr.press/v119/xiao20b.html">theoretically</a> and <a href="https://arxiv.org/abs/2007.15801">experimentally</a>, and released <a href="https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html">Neural Tangents</a>, an <a href="https://github.com/google/neural-tangents">open-source software library</a> written in <a href="https://github.com/google/jax">JAX</a> that allows researchers to build and train infinite-width neural networks.  </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-zGI3hx_BGfg/X_3mYLg3s_I/AAAAAAAAG-I/L6DjbxrgPQs6jU776QcGjOEn_KKPp5HnwCLcBGAsYHQ/s640/image33.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="225" src="https://1.bp.blogspot.com/-zGI3hx_BGfg/X_3mYLg3s_I/AAAAAAAAG-I/L6DjbxrgPQs6jU776QcGjOEn_KKPp5HnwCLcBGAsYHQ/w400-h225/image33.gif" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><b>Left:</b> A schematic showing how deep neural networks induce simple input / output maps as they become infinitely wide. <b>Right:</b> As the width of a neural network increases, we see that the distribution of outputs over different random instantiations of the network becomes Gaussian.</td></tr></tbody></table><br /><p>As finite width networks are made larger, they also demonstrate peculiar <em>double descent </em>phenomena — where they generalize better, then worse, then better again with increasing width. We have shown that this phenomenon can be explained by a novel <a href="http://proceedings.mlr.press/v119/adlam20a">bias-variance decomposition, and further that it can sometimes manifest as triple descent</a>. </p><p>Lastly, in real-world problems, one often needs to deal with significant label noise. For instance, in large scale learning scenarios, weakly labeled data is available in abundance with large label noise. We have developed new techniques for <a href="https://research.google/pubs/pub49038/">distilling effective supervision from severe label noise</a> leading to state-of-the-art results. We have further analyzed the effects of <a href="https://research.google/pubs/pub49817/">training neural networks with random labels</a>, and shown that it leads to alignment between network parameters and input data, enabling faster downstream training than initializing from scratch. We have also explored questions such as whether <a href="http://proceedings.mlr.press/v119/lukasik20a.html">label smoothing</a> or <a href="https://research.google/pubs/pub48960/">gradient clipping</a> can mitigate label noise, leading to new insights for developing robust training techniques with noisy labels. </p><p><b>Algorithmic Foundations and Theory</b><br />2020 was a productive year for our work in algorithmic foundations and theory, with several impactful research publications and notable results. On the optimization front, our paper on <a href="https://research.google/pubs/pub49768/">edge-weighted online bipartite matching</a> develops a new technique for online <a href="https://en.wikipedia.org/wiki/Competitive_analysis_(online_algorithm)">competitive algorithms</a> and solves a<a href="https://people.eecs.berkeley.edu/~vazirani/pubs/online.pdf"> thirty-year old open problem</a> for the edge-weighted variant with applications in efficient online ad allocation. Along with this work in online allocation, we developed <a href="https://arxiv.org/pdf/2002.10421.pdf">dual mirror descent techniques</a> that generalize to a variety of models with additional diversity and <a href="https://arxiv.org/abs/2007.00514">fairness</a> constraints, and published a sequence of papers on the topic of online optimization with ML advice in<a href="https://research.google/pubs/pub48659/"> online scheduling</a>, <a href="http://proceedings.mlr.press/v119/bhaskara20a.html">online learning</a> and <a href="https://papers.nips.cc/paper/2020/file/6c250b592dc94d4de38a79db4d2b18f2-Paper.pdf">online linear optimization</a>. <a href="https://arxiv.org/abs/2009.01802">Another research result</a> gave the first improvement in 50 years on the classic bipartite matching in dense graphs. Finally, another<a href="https://arxiv.org/abs/1905.11877"> paper</a> solves a long-standing open problem about chasing convex bodies online — using <a href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/">an algorithm from The Book</a>, no less.  </p><p>We also continued our work in scalable graph mining and graph-based learning and hosted the <a href="https://gm-neurips-2020.github.io/">Graph Mining &amp; Learning at Scale Workshop</a> at NeurIPS’20, which covered work on scalable graph algorithms including graph clustering, graph embedding, causal inference, and graph neural networks. As part of the workshop, we showed how to <a href="https://dl.acm.org/doi/abs/10.14778/3424573.3424579">solve several fundamental graph problems faster, both in theory and practice</a>, by augmenting standard synchronous computation frameworks like <a href="https://research.google/pubs/pub62/">MapReduce</a> with a distributed hash-table similar to a <a href="https://research.google/pubs/pub27898/">BigTable</a>. Our extensive empirical study validates the practical relevance of the <a href="https://dl.acm.org/doi/10.1145/3323165.3323208">AMPC model</a> inspired by our use of distributed hash tables in massive parallel algorithms for hierarchical clustering and connected components, and our theoretical results show how to solve many of these problems in constant distributed rounds, greatly improving upon our <a href="https://arxiv.org/abs/1910.05385">previous results</a>. We also achieved exponential speedup for <a href="https://dl.acm.org/doi/10.1145/3357713.3384303">computing PageRank and random walks</a>. On the graph-based learning side, we presented <a href="https://dl.acm.org/doi/abs/10.1145/3394486.3403302">Grale</a>, our framework for designing graphs for use in machine learning. Furthermore, we presented our work on more <a href="https://dl.acm.org/doi/abs/10.1145/3394486.3403296">scalable graph neural network models</a>, where we show that <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> can be used to greatly accelerate inference in GNNs.  </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-jD8HUXS0vnM/X_3mvdJqQuI/AAAAAAAAG-Q/niEne_c3KbUeprRA-CtIYaYEGldZJls4QCLcBGAsYHQ/s715/image13.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="400" src="https://1.bp.blogspot.com/-jD8HUXS0vnM/X_3mvdJqQuI/AAAAAAAAG-Q/niEne_c3KbUeprRA-CtIYaYEGldZJls4QCLcBGAsYHQ/w311-h400/image13.png" width="311" /></a></div><p>In market algorithms, an area at the intersection of computer science and economics, we continued our research in designing improved online marketplaces, such as <a href="https://research.google/pubs/pub49036/">measuring incentive properties of ad auctions</a>, <a href="https://research.google/pubs/pub49473/"> two-sided markets</a>, and <a href="https://papers.nips.cc/paper/2020/file/b6417f112bd27848533e54885b66c288-Paper.pdf">optimizing order statistics in ad selection</a>. In the area of repeated auctions, we developed frameworks to make dynamic mechanisms robust against <a href="https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA15530">lack of forecasting</a> or estimation errors of <a href="https://papers.nips.cc/paper/2019/hash/8685549650016d9e1d14bf972262450b-Abstract.html">the current market</a> and/or <a href="http://proceedings.mlr.press/v119/deng20d.html">the future market</a>, leading to provably tight low-regret dynamic mechanisms. Later, we characterized when it is possible to <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3716352">achieve the asymptotically optimal objective</a> through geometry-based criteria. We also <a href="https://dx.doi.org/10.2139/ssrn.2858261">compared the equilibrium outcome of a range of budget management strategies</a> used in practice, showed their impact on the tradeoff between revenue and buyers' utility and <a href="https://dl.acm.org/doi/10.1145/3391403.3399472">shed light on their incentive properties</a>. Additionally, we continued our research in learning optimal auction parameters, and settled the <a href="https://proceedings.neurips.cc//paper/2020/file/67e235e7f2fa8800d8375409b566e6b6-Paper.pdf">complexity of batch-learning with revenue loss</a>. We designed the <a href="https://arxiv.org/abs/2003.01703">optimal regret</a> and <a href="https://papers.nips.cc/paper/2020/file/0e1bacf07b14673fcdb553da51b999a5-Paper.pdf">studied combinatorial optimization</a> for contextual auction pricing, and developed a <a href="http://proceedings.mlr.press/v125/paes-leme20a.html">new active learning framework for auctions</a> and <a href="https://arxiv.org/abs/1807.03435">improved the approximation for posted-price auctions</a>. Finally, motivated by the importance of incentives in ad auctions, and in the hope to help advertisers study the impact of incentives in auctions, we introduce a <a href="https://research.google/pubs/pub49036/">data-driven metric to quantify how much a mechanism deviates from incentive compatibility</a>.</p><p><b>Machine Perception</b><br />Perceiving the world around us — understanding, modeling and acting on visual, auditory and multimodal input — continues to be a research area with tremendous potential to be beneficial in our everyday lives. </p><p>In 2020, deep learning powered new approaches that bring 3D computer vision and computer graphics closer together. <a href="https://arxiv.org/pdf/1909.05736.pdf">CvxNet</a>, <a href="https://arxiv.org/pdf/1912.06126.pdf">deep implicit functions for 3D shapes</a>, <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Rematas_Neural_Voxel_Renderer_Learning_an_Accurate_and_Controllable_Rendering_Tool_CVPR_2020_paper.html">neural voxel rendering</a> and <a href="https://arxiv.org/pdf/2004.12989.pdf">CoReNet</a> are a few examples of this direction. Furthermore, our research on representing scenes as neural radiance fields (aka <a href="https://www.matthewtancik.com/nerf">NeRF</a>, see also this <a href="https://dellaert.github.io/NeRF/">blog post</a>) is a good example of how Google Research's academic collaborations stimulate rapid progress in the area of neural volume rendering. </p><div style="text-align: center;"><a href="https://1.bp.blogspot.com/-_f0LiWkw8mQ/X_3n5XxUX3I/AAAAAAAAG-c/VyjJXSPonnQdwW5eV3g9zqGU8OwhiCTBACLcBGAsYHQ/s1253/image2.png"><img border="0" height="154" src="https://1.bp.blogspot.com/-_f0LiWkw8mQ/X_3n5XxUX3I/AAAAAAAAG-c/VyjJXSPonnQdwW5eV3g9zqGU8OwhiCTBACLcBGAsYHQ/w640-h154/image2.png" width="640" /></a></div><p>In <a href="https://factorize-a-city.github.io/">Learning to Factorize and Relight a City</a>, a collaboration with UC Berkeley, we proposed a learning-based framework for disentangling outdoor scenes into temporally-varying illumination and permanent scene factors. This gives the ability to change lighting effects and scene geometry for any Street View panorama, or even turn it into a full-day timelapse video. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-SyDShKdnCPs/X_3oBWKXIRI/AAAAAAAAG-g/od6iXCO1x-sscSuC0YHel1DRThPoKx7qQCLcBGAsYHQ/s1460/image27.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="146" src="https://1.bp.blogspot.com/-SyDShKdnCPs/X_3oBWKXIRI/AAAAAAAAG-g/od6iXCO1x-sscSuC0YHel1DRThPoKx7qQCLcBGAsYHQ/w640-h146/image27.gif" width="640" /></a></div><p>Our work on <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_GHUM__GHUML_Generative_3D_Human_Shape_and_Articulated_Pose_CVPR_2020_paper.pdf">generative human shape and articulated pose models</a> introduces a statistical, articulated 3D human shape modeling pipeline, within a fully trainable, modular, deep learning framework. Such models enable 3D human pose and shape reconstruction of people from a single photo to better understand the scene. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-qRukOQQ_meY/X_3oKTJzeyI/AAAAAAAAG-o/Op13X1iveWYO8H8f0kbnlY9W78w_5YeWgCLcBGAsYHQ/s1260/image10.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="350" src="https://1.bp.blogspot.com/-qRukOQQ_meY/X_3oKTJzeyI/AAAAAAAAG-o/Op13X1iveWYO8H8f0kbnlY9W78w_5YeWgCLcBGAsYHQ/w640-h350/image10.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Overview of end-to-end statistical 3D articulated human shape model construction in <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_GHUM__GHUML_Generative_3D_Human_Shape_and_Articulated_Pose_CVPR_2020_paper.pdf">GHUM &amp; GHUML: Generative 3D Human Shape and Articulated Pose Models</a>.</td></tr></tbody></table><p>The growing area of media compression using neural networks continued to make strong progress in 2020, not only on <a href="http://www.compression.cc/">learned image compression</a>, but also in deep approaches to <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Agustsson_Scale-Space_Flow_for_End-to-End_Optimized_Video_Compression_CVPR_2020_paper.html">video compression</a>, <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Tang_Deep_Implicit_Volume_Compression_CVPR_2020_paper.html">volume compression</a> and nice results in deep <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Luo_Distortion_Agnostic_Deep_Watermarking_CVPR_2020_paper.html">distortion-agnostic image watermarking</a>. </p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-fhdZSqrVYmA/X_3oyKlNKMI/AAAAAAAAG-4/y6gqdjLQopU-A8MSlR8N44RY40kAxj01ACLcBGAsYHQ/s1148/image8.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="328" src="https://1.bp.blogspot.com/-fhdZSqrVYmA/X_3oyKlNKMI/AAAAAAAAG-4/y6gqdjLQopU-A8MSlR8N44RY40kAxj01ACLcBGAsYHQ/w400-h328/image8.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Samples of encoded and cover images for <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Distortion_Agnostic_Deep_Watermarking_CVPR_2020_paper.pdf">Distortion Agnostic Deep Watermarking</a>. <b>First row:</b> Cover image with no embedded message. <b>Second row:</b> Encoded image from HiDDeN combined distortion model. <b>Third row:</b> Encoded images from our model. <b>Fourth row:</b> Normalized difference of the encoded image and cover image for the HiDDeN combined model. <b>Fifth row:</b> Normalized difference for our model</td></tr></tbody></table><p>Additional important themes in perceptual research included: </p><ul><li>Making better use of data (e.g., <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Xie_Self-Training_With_Noisy_Student_Improves_ImageNet_Classification_CVPR_2020_paper.html">self-training with noisy students</a>, <a href="https://arxiv.org/pdf/2007.15506.pdf">learning from simulated data</a>, <a href="https://ai.googleblog.com/2020/08/understanding-deep-learning-on.html">learning with noisy labels</a>, <a href="https://ai.googleblog.com/2020/08/understanding-view-selection-for.html">contrastive learning</a>) </li><li>Reasoning across modalities (e.g., <a href="https://arxiv.org/pdf/2003.13594.pdf">exploiting cross-modal supervision</a>, <a href="http://ai.googleblog.com/2020/10/audiovisual-speech-enhancement-in.html">audiovisual speech enhancement</a>, <a href="http://ai.googleblog.com/2020/02/enhancing-research-communitys-access-to.html">language grounding</a>, <a href="https://ai.googleblog.com/2020/02/open-images-v6-now-featuring-localized.html">Open Images (V6) update featuring localized narratives</a> — multimodal annotations connecting vision and language) </li><li>Developing approaches for efficient perception, particularly on edge devices (e.g., <a href="https://arxiv.org/pdf/1911.09723.pdf">fast sparse convnets</a>, <a href="https://arxiv.org/pdf/1911.11177.pdf">structured multi-hashing for model compression</a>) </li><li>Improving the ability to represent and reason about objects and scenes (e.g., <a href="https://arxiv.org/pdf/2004.01170.pdf">detecting 3D objects and predicting 3D shapes</a>, <a href="https://arxiv.org/pdf/2004.12989.pdf">3D scene reconstruction from a single RGB image</a>, <a href="http://ai.googleblog.com/2020/06/leveraging-temporal-context-for-object.html">leveraging temporal context for object detection</a>, <a href="http://ai.googleblog.com/2020/02/learning-to-see-transparent-objects.html">learning to see transparent objects</a> and <a href="https://ai.googleblog.com/2020/09/keypose-estimating-3d-pose-of.html">estimating their pose from stereo</a>) </li><li>AI enabling human creativity (e.g., <a href="http://ai.googleblog.com/2020/10/experimenting-with-automatic-video.html">automatic creation of videos from web pages</a>, <a href="http://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html">intelligent video reframing</a>, <a href="http://ai.googleblog.com/2020/11/using-gans-to-create-fantastical.html">using GANs to create fantastical creatures</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">relighting portraits</a>) </li></ul><p>Engaging with the broader research community through open sourcing of solutions and datasets is another important aspect of furthering perceptual research. In 2020, we open sourced multiple new perceptual inference capabilities and solutions in <a href="https://mediapipe.dev/">MediaPipe</a>, such as <a href="https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html">on-device face, hand and pose prediction</a>, <a href="http://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html">real-time body pose tracking</a>, <a href="http://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html">real-time iris tracking and depth estimation</a>, and <a href="http://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html">real-time 3D object detection</a>. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Fp2G-1tiHuY/X_3pBCU5sQI/AAAAAAAAG-8/BAkR8TipFqAaQpn_pVwjDKygTBeY0ONxACLcBGAsYHQ/s712/image5.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="225" src="https://1.bp.blogspot.com/-Fp2G-1tiHuY/X_3pBCU5sQI/AAAAAAAAG-8/BAkR8TipFqAaQpn_pVwjDKygTBeY0ONxACLcBGAsYHQ/w400-h225/image5.gif" width="400" /></a></div><p>We continued to make strides to improve experiences and promote helpfulness on mobile devices through ML-based solutions. Our ability to run sophisticated natural language processing on-device, enabling more natural conversational features, continues to improve. In 2020, we expanded <a href="https://blog.google/technology/ai/duplex-helpful-updates/">Call Screen</a> and launched <a href="https://blog.google/products/pixel/hold-for-me/">Hold for Me</a> to allow users to save time when performing mundane tasks, and we also launched <a href="http://ai.googleblog.com/2020/07/grounding-natural-language-instructions.html">language-based actions</a> and <a href="http://ai.googleblog.com/2020/11/navigating-recorder-transcripts-easily.html">language navigability of our Recorder app</a> to aid productivity.  </p><p>We have used Google's <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex</a> technology to make calls to businesses and confirm things like temporary closures. This has <a href="https://blog.google/technology/ai/duplex-helpful-updates/">enabled</a> us to make 3 million updates to business information globally, that have been seen over 20 billion times on Maps and Search. We also used text to speech technology for easier access to web pages, by enabling Google Assistant to<a href="https://www.blog.google/products/assistant/easier-access-web-pages-let-assistant-read-it-aloud/"> read it aloud</a>, supporting 42 languages.  </p><p>We also continued to make meaningful improvements to imaging applications. We made it easier to <a href="https://blog.google/products/pixel/take-holiday-photos-night-sight-portrait-mode/">capture</a> precious moments on Pixel with <a href="https://ai.googleblog.com/2020/08/live-hdr-and-dual-exposure-controls-on.html">innovative controls</a> and new ways to <a href="http://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">relight</a>, <a href="https://blog.google/products/photos/new-helpful-editor/">edit</a>, <a href="https://blog.google/products/pixel/december-feature-drop/">enhance</a> and <a href="https://blog.google/products/photos/new-cinematic-photos-and-more-ways-relive-your-memories/">relive</a> them again in Google Photos. For the Pixel camera, beginning with Pixel 4 and 4a, we added <a href="https://ai.googleblog.com/2020/08/live-hdr-and-dual-exposure-controls-on.html">Live HDR+</a>, which uses machine learning to approximate the vibrance and balanced exposure and appearance of <a href="https://ai.googleblog.com/2018/02/introducing-hdr-burst-photography.html">HDR+ burst photography</a> in real time in the viewfinder. We also created dual exposure controls, which allow the brightness of shadows and highlights in a scene to be adjusted independently — live in the viewfinder.  </p><p>More recently, we introduced <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, a new post-capture feature for the Pixel Camera and Google Photos apps that adds a simulated directional light source to portraits.  This feature is again one that is powered by machine learning, having been trained on 70 different people, photographed one light at a time, in our pretty cool 331-LED <a href="https://augmentedperception.github.io/therelightables/">Light Stage</a> computational illumination system. </p><div class="separator" style="clear: both; text-align: center;"></div><p>In the past year, Google researchers were excited to contribute to many new (and timely) ways of using Google products. Here are a few examples </p><ul><li>Enhancing learning by making it easier to <a href="https://blog.google/products/search/visual-ways-search-and-understand-our-world/">get help with homework or explore concepts in 3D</a> via augmented reality </li><li>Improving virtual meetings via in-browser <a href="http://ai.googleblog.com/2020/10/background-features-in-google-meet.html">background blur &amp; replace in Google Meet</a>. <div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-FUi589HnqhE/X_3pKn1NRgI/AAAAAAAAG_E/POlkuWbSa9MvYMpE1feeVfSjGkKmHbmYgCLcBGAsYHQ/s960/image13.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="181" src="https://1.bp.blogspot.com/-FUi589HnqhE/X_3pKn1NRgI/AAAAAAAAG_E/POlkuWbSa9MvYMpE1feeVfSjGkKmHbmYgCLcBGAsYHQ/w640-h181/image13.gif" width="640" /></a></div></li><li>Powering new ways to virtually <a href="https://blog.google/products/shopping/shopping-beauty-product-try-it-google/">try products on</a> at home. </li><li>Helping you get to the most relevant content faster via <a href="https://blog.google/products/search/search-on/">key moments in video</a>. </li><li>Helping you find that tune that was stuck in your head by <a href="https://ai.googleblog.com/2020/11/the-machine-learning-behind-hum-to.html">humming</a> it. </li><li>Helped YouTube <a href="https://blog.youtube/inside-youtube/responsible-policy-enforcement-during-covid-19/">identify potentially harmful content for human review</a>. </li><li>Helping YouTube creators make better videos by automatically <a href="https://ai.googleblog.com/2020/10/audiovisual-speech-enhancement-in.html">enhancing their voices and reducing background noise</a>. </li></ul><p><b>Robotics</b><br />In the area of <a href="http://g.co/robotics">robotics research</a>, we’ve made tremendous progress in our ability to learn more and more complex, safe and robust robot behaviors with less and less data, using many of the RL techniques described earlier in the post. </p><p><a href="https://transporternets.github.io/">Transporter Networks</a> are a novel approach to learning how to represent robotic tasks as spatial displacements. Representing relations between objects and the robot end-effectors, as opposed to absolute positions in the environment, makes learning robust transformations of the workspace very efficient. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-efYiVCFWOnM/X_3rULZpnEI/AAAAAAAAG_U/MEMg9qhgRpcNkxGl1UVr4ZLRqGbk6qaPgCLcBGAsYHQ/s481/image18.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="266" src="https://1.bp.blogspot.com/-efYiVCFWOnM/X_3rULZpnEI/AAAAAAAAG_U/MEMg9qhgRpcNkxGl1UVr4ZLRqGbk6qaPgCLcBGAsYHQ/w400-h266/image18.gif" width="400" /></a></div><p>In <a href="https://language-play.github.io/">Grounding Language in Play</a>, we demonstrated how a robot can be taught to follow natural language instructions (in many languages!). This required a scalable approach to collecting paired data of natural language instructions and robot behaviors. One key insight is that this can be accomplished by asking robot operators to simply <a href="https://learning-from-play.github.io/">play with the robot</a>, and label after-the-fact what instructions would have led to the robot accomplishing the same task. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-ekmocHwP5Ts/X_3rcuBO_7I/AAAAAAAAG_Y/mSFYFnrVK-0sMEMmY9e6Ou6ol3DchrjnwCLcBGAsYHQ/s400/image31.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="336" src="https://1.bp.blogspot.com/-ekmocHwP5Ts/X_3rcuBO_7I/AAAAAAAAG_Y/mSFYFnrVK-0sMEMmY9e6Ou6ol3DchrjnwCLcBGAsYHQ/w400-h336/image31.gif" width="400" /></a></div><p>We also explored <a href="https://graspinwild.cs.columbia.edu/">doing away with robots altogether</a> (by having humans use a camera-equipped grasping stick) for even more scalable data collection, and how to efficiently <a href="https://ai.googleblog.com/2020/03/visual-transfer-learning-for-robotic.html">transfer visual representations</a> across robotic tasks. </p><p>We investigated how to learn very agile strategies for robot locomotion, by <a href="http://ai.googleblog.com/2020/04/exploring-nature-inspired-robot-agility.html">taking inspiration from nature</a>, using <a href="http://ai.googleblog.com/2020/04/exploring-evolutionary-meta-learning-in.html">evolutionary meta-learning</a> strategies, <a href="https://research.google/pubs/pub48968/">human demonstrations</a>, and various approaches to training <a href="https://ai.googleblog.com/2020/05/agile-and-intelligent-locomotion-via.html">data-efficient controllers</a> using deep reinforcement learning. </p><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-st3f3svMOZ8/X_3rn9KJXNI/AAAAAAAAG_g/NY2xf6rIBgYhjuSitcn-1KCZd9JyAdZlgCLcBGAsYHQ/s600/image19.gif" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="318" src="https://1.bp.blogspot.com/-st3f3svMOZ8/X_3rn9KJXNI/AAAAAAAAG_g/NY2xf6rIBgYhjuSitcn-1KCZd9JyAdZlgCLcBGAsYHQ/w640-h318/image19.gif" width="640" /></a></div><p>One increased emphasis this year has been on safety: how do we deploy <a href="https://research.google/pubs/pub49251/">safe delivery drones</a> in the real world? How do we <a href="https://arxiv.org/abs/2010.15920">explore the world</a> in a way that always allows the robot to recover from its mistakes? How do we <a href="https://arxiv.org/abs/2008.05952">certify the stability</a> of learned behaviors? This is a critical area of research on which we expect to see increased focus in the future. </p><p><b>Quantum Computing</b><br />Our <a href="https://quantumai.google/">Quantum AI</a> team continued its work to establish practical uses of quantum computing. We ran experimental algorithms on our <a href="https://www.youtube.com/watch?v=crpQexwT2HU">Sycamore processors</a> to simulate systems relevant to <a href="https://ai.googleblog.com/2020/08/scaling-up-fundamental-quantum.html">chemistry</a> and <a href="https://quantumai.google/cirq/experiments/fermi_hubbard">physics</a>. These simulations are approaching a scale at which they can not be performed on classical computers anymore, making good on Feynman’s original idea of using quantum computers as an efficient means to simulate systems in which quantum effects are important. We published new quantum algorithms, for instance to perform precise processor calibration, to show an advantage for <a href="https://research.google/pubs/pub49725/">quantum machine learning</a> or to test <a href="https://research.google/pubs/pub49058/">quantum enhanced optimization</a>. We also worked on programming models to <a href="https://ai.googleblog.com/2020/03/announcing-tensorflow-quantum-open.html">make it easier to express quantum algorithms</a>. We released <a href="https://blog.google/technology/ai/qsim-explore-quantum-algorithms/">qsim</a>, an efficient simulation tool to develop and test quantum algorithms with up to 40 qubits on Google Cloud.  </p><p>We continued to follow our <a href="https://www.youtube.com/watch?v=TJ6vBNEQReU">roadmap towards building a universal error-corrected quantum computer</a>. Our next milestone is the demonstration that quantum error correction can work in practice. To achieve this, we will show that a larger grid of qubits can hold logical information exponentially longer than a smaller grid, even though individual components such as qubits, couplers or I/O devices have imperfections. We are also particularly excited that we now have our own cleanroom which should significantly increase the speed and quality of our processor fabrication. </p><p><b>Supporting the Broader Developer and Researcher Community</b><br />This year marked TensorFlow’s <a href="https://blog.google/technology/ai/5-ways-celebrate-tensorflows-5th-birthday/">5th birthday</a>, passing 160M downloads. The TensorFlow community continued its impressive growth with <a href="https://blog.tensorflow.org/2020/12/join-tensorflow-special-interest-groups.html">new special interest groups</a>, <a href="https://blog.tensorflow.org/2020/11/videos-from-tensorflow-user-group-summit-india.html">TensorFlow User Groups</a>, <a href="https://blog.tensorflow.org/2020/03/introducing-tensorflow-developer-certificate.html">TensorFlow Certificates</a>, <a href="https://blog.tensorflow.org/2020/12/meet-our-tensorflow-ai-service-partners.html">AI Service partners</a>, and inspiring demos <a href="https://twitter.com/hashtag/TFCommunitySpotlight">#TFCommunitySpotlight</a>. We significantly improved TF 2.x with seamless TPU support, out of the box performance (<a href="https://blog.tensorflow.org/2020/07/tensorflow-2-mlperf-submissions.html">and best-in-class performance on MLPerf 0.7</a>), <a href="https://blog.tensorflow.org/2020/07/whats-new-in-tensorflow-2-3.html">data preprocessing</a>, <a href="https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html">distribution strategy</a>, and a <a href="https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html">new NumPy API</a>. </p><p>We also added many more capabilities to the TensorFlow Ecosystem to help developers and researchers in their workflows: <a href="https://blog.tensorflow.org/2020/08/creating-sounds-of-india-with-tensorflow.html">Sounds of India</a> demonstrated going from research to production in under 90 days, using <a href="https://www.tensorflow.org/tfx">TFX</a> for training and <a href="https://www.tensorflow.org/js">TF.js</a> for deployment in the browser. With <a href="https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow">Mesh TensorFlow</a>, we pushed the boundaries of model parallelism to provide<a href="https://ai.googleblog.com/2020/02/ultra-high-resolution-image-analysis.html"> ultra-high image resolution image analysis</a>. We open-sourced the new <a href="https://blog.tensorflow.org/2020/04/tfrt-new-tensorflow-runtime.html">TF runtime</a>, <a href="https://blog.tensorflow.org/2020/04/introducing-new-tensorflow-profiler.html">TF Profiler</a> for model performance debugging, and <a href="https://www.tensorflow.org/responsible_ai">tools for Responsible AI</a>, such as the<a href="https://blog.tensorflow.org/2020/11/using-model-card-toolkit-for-tf-model-transparency.html"> Model Card Toolkit</a> for model transparency and a <a href="https://blog.tensorflow.org/2020/06/introducing-new-privacy-testing-library.html">privacy testing library</a>. With <a href="https://blog.tensorflow.org/2019/12/introducing-tensorboarddev-new-way-to.html">TensorBoard.dev</a> we made it possible to easily host, track, and share your ML experiments for free. </p><p>In addition, we redoubled our investment in <a href="https://github.com/google/jax">JAX</a>, an open-source, research-focused ML system that has been actively developed over the past two years. Researchers at Google and beyond are now using JAX in a wide range of fields, including <a href="https://arxiv.org/abs/2010.09063">differential privacy</a>, <a href="https://github.com/google-research/google-research/tree/master/jaxnerf">neural rendering</a>, <a href="https://arxiv.org/abs/2003.04630">physics-informed networks</a>, <a href="https://github.com/google-research/google-research/tree/master/performer/fast_attention">fast attention</a>, <a href="https://github.com/google/jax-md">molecular dynamics</a>, <a href="https://github.com/google/TensorNetwork">tensor networks</a>, <a href="https://github.com/google/neural-tangents">neural tangent kernels</a>, and <a href="https://twitter.com/DavidDuvenaud/status/1284181667553390595">neural ODEs</a>. JAX <a href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research">accelerates research at DeepMind</a>, powering a growing <a href="https://www.youtube.com/watch?v=iDxJxIyzSiM">ecosystem of libraries and work on GANs, meta-gradients, reinforcement learning, and more</a>. We also used JAX and the <a href="https://github.com/google/flax">Flax neural network library</a> to build <a href="https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer">record-setting MLPerf benchmark submissions</a>, which we demonstrated live at NeurIPS on a large TPU Pod slice with a next-generation Cloud TPU user experience (<a href="https://docs.google.com/presentation/d/1eBfNKT3D3lEWtcn4mkgvvitKZTU7HSn4f3fGHqYgpeA/edit?resourcekey=0-1OKIlteFVZe5VeFi_1_1mw#slide=id.gaf35bf4b78_3_18">slides</a>, <a href="https://drive.google.com/file/d/1jKxefZT1xJDUxMman6qrQVed7vWI0MIn/edit">video</a>, <a href="https://docs.google.com/forms/d/e/1FAIpQLScg4QszgSCM9RxdlLiafYt3STnqe-qBs_KuNIEZd7_8_TRMAQ/viewform">sign-up form</a>). Finally, we’re ensuring that JAX works seamlessly with TF ecosystem tooling, from <a href="https://www.tensorflow.org/api_docs/python/tf/data">TF.data</a> for data preprocessing and <a href="https://www.tensorflow.org/tensorboard">TensorBoard</a> for experiment visualization to the <a href="https://blog.tensorflow.org/2020/04/introducing-new-tensorflow-profiler.html">TF Profiler</a> for performance debugging, with more to come in 2021. </p><p>Many recent research breakthroughs have been enabled by increased computing power, and we make more than 500 petaflops of Cloud TPU computing power available for free to researchers around the world via the <a href="https://www.tensorflow.org/tfrc">TFRC program</a> to help broaden access to the machine learning research frontier. More than 120 TFRC-supported papers have been published to date, many of which would not have been possible without the computing resources that the program provides. For example, TFRC researchers have recently developed <a href="http://meetings.aps.org/Meeting/DFD20/Session/P04.5">simulations of wildfire spread</a>, <a href="https://arxiv.org/pdf/2005.07503.pdf">helped analyze COVID-19 content</a> and <a href="https://arxiv.org/pdf/2012.02197.pdf">vaccine sentiment changes</a> on social media networks, and advanced our collective understanding of <a href="https://arxiv.org/abs/1912.05671">the lottery ticket hypothesis</a> and <a href="https://arxiv.org/abs/2006.10621">neural network pruning</a>. Members of the TFRC community have also published <a href="https://medium.com/@khashei/writing-persian-poetry-with-gpt-2-0-71b7197317ea">experiments with Persian poetry</a>, <a href="https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7/discussion/154306">won a Kaggle contest on fine-grained fashion image segmentation</a>, and shared <a href="https://github.com/sackoh/pycon-korea-2020-kb-albert">tutorials</a> and <a href="https://github.com/trisongz/tpubar">open-source tools</a> as starting points for others. In 2021, we will change the name of the TFRC program to the TPU Research Cloud program to be more inclusive now that Cloud TPUs support <a href="https://docs.google.com/presentation/d/1eBfNKT3D3lEWtcn4mkgvvitKZTU7HSn4f3fGHqYgpeA/edit?resourcekey=0-1OKIlteFVZe5VeFi_1_1mw#slide=id.gaf35bf4b78_3_18">JAX</a> and <a href="https://cloud.google.com/blog/products/ai-machine-learning/pytorch-is-now-ga-on-google-cloud-tpus">PyTorch</a> in addition to TensorFlow. </p><p>Finally, this was a huge year for <a href="https://colab.research.google.com/">Colab</a>. Usage doubled, and we launched productivity features to help people do their work more efficiently, including <a href="https://twitter.com/GoogleColab/status/1226929213560610818">improved Drive integration</a> and access to the Colab VM <a href="https://twitter.com/GoogleColab/status/1336698772760379392">via the terminal</a>. And we launched <a href="http://feeds.feedburner.com/blogspot/colab.research.google.com/signup">Colab Pro</a> to enable users to access faster GPUs, longer runtimes and more memory. </p><p><b>Open Datasets and Dataset Search</b><br />Open datasets with clear and measurable goals are often very helpful in driving forward the field of machine learning. To help the research community find interesting datasets, we continue to index a wide variety of open datasets sourced from many different organizations with <a href="https://toolbox.google.com/datasetsearch">Google Dataset Search</a>. We also think it's important to create new datasets for the community to explore and to develop new techniques, while ensuring that we <a href="https://www.blog.google/technology/ai/sharing-open-data/">share open data responsibly</a>. This year, in addition to <a href="https://github.com/GoogleCloudPlatform/covid-19-open-data">open datasets to help address the COVID crisis</a>, we released a number of open datasets across many different areas: </p><ul><li><a href="http://ai.googleblog.com/2020/08/an-analysis-of-online-datasets-using.html">An Analysis of Online Datasets Using Dataset Search (Published, in Part, as a Dataset)</a>: a meta dataset about datasets! </li><li><a href="http://ai.googleblog.com/2020/04/yet-more-google-compute-cluster-trace.html">Google Compute Cluster Trace Data</a>: in 2011, Google published a trace of 29 days of compute activity on one of our compute clusters, which has proven very useful for the computer systems community to explore job scheduling policies, better understand utilization in these clusters, etc. This year we published a larger and more extensive version of this data, covering eight of our compute clusters with much finer-grained information. </li><li><a href="http://ai.googleblog.com/2020/11/announcing-objectron-dataset.html">Announcing the Objectron Dataset</a>: a collection of 15,000 short, object-centric video clips annotated with 3-D bounding boxes, capturing a larger set of common objects from different angles, as well as 4M annotated images collected from a geo-diverse sample (covering 10 countries across five continents). </li><li><a href="https://ai.googleblog.com/2020/02/open-images-v6-now-featuring-localized.html">Open Images V6 — Now Featuring Localized Narratives</a>: in addition to the 9M images annotated with 36M image-level labels, 15.8M bounding boxes, 2.8M instance segmentations, and 391k visual relationships found in version 5, this new release adds localized narratives, a completely new form of multimodal annotations that consist of synchronized voice, text, and mouse traces over the objects being described. In Open Images V6, these localized narratives are available for 500k of its images. Additionally, in order to facilitate comparison to previous works, we also release localized narratives annotations for the full 123k images of the COCO dataset. </li><li><a href="http://ai.googleblog.com/2020/06/presenting-challenge-and-workshop-in.html">A Challenge and Workshop in Efficient Open-Domain Question Answering</a>, created in collaboration with researchers from University of Washington and Princeton, aims to challenge researchers to create systems capable of answering arbitrary questions. A <a href="https://efficientqa.github.io/assets/report.pdf">technical report</a> describes the competition and workshop that happened at NeurIPS 2020.   </li><li><a href="http://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html">TyDi QA: A Multilingual Question Answering Benchmark</a> discusses a new benchmark for measuring effectiveness of multilingual question answering (since many benchmarks in this area are English-only or otherwise monolingual, and we feel answering questions in any language is important).   </li><li><a href="https://research.google/pubs/pub49029/">Wiki-40B: Multilingual Language Model Dataset</a> is a new multilingual language model benchmark that is composed of 40+ languages spanning several scripts and linguistic families. With around 40 billion characters, we hope this new resource will accelerate the research of multilingual modeling. We also released high quality trained language models trained on this dataset, enabling easy comparison of different techniques with these baselines.   </li><li><a href="http://ai.googleblog.com/2020/04/xtreme-massively-multilingual-multi.html">XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization</a> can help assess progress on cross-lingual generalizations in a multi-task setting.   </li><li><a href="https://research.google/pubs/pub48780/">How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for Rewriting Ill-Formed Questions</a> presents a dataset of 427,719 question pairs across 303 domains that can be used to train models to rewrite poorly-formed questions into better formulations.   </li><li><a href="http://ai.googleblog.com/2020/05/open-sourcing-bit-exploring-large-scale.html">Open-Sourcing Big Transfer (BiT): Exploring Large-Scale Pre-training for Computer Vision</a> describes an open-sourced pre-trained model that can be used as a starting point for a wide variety of image-related tasks.   </li><li><span style="text-decoration: underline;"><a href="https://ai.googleblog.com/2020/04/announcing-2020-image-matching.html">The 2020 Image Matching Benchmark and Challenge</a></span> is a dataset and benchmark challenge for the problem of capturing 3D structure from motion (either from videos, or from many images of a scene from many different angles), created in collaboration with <a href="http://feeds.feedburner.com/blogspot/www.uvic.ca">University of Victoria</a>, <a href="http://cvut.cz/en">Czech Technical University</a>, and <a href="http://feeds.feedburner.com/blogspot/epfl.ch/en">EPFL</a>.   </li><li><a href="http://ai.googleblog.com/2020/05/announcing-meta-dataset-dataset-of.html">Meta-Dataset: A Dataset of Datasets for Few-Shot Learning</a> is a dataset of datasets. One of the long-term goals in ML is to build systems that can generalize not from one example to another within the same task, but can generalize even across tasks to solve new problems with little or no training. This meta-dataset can allow us to measure progress towards this ultimate goal.   </li><li><a href="https://research.google/pubs/pub49052/">Google Landmarks Dataset v2 - A Large-Scale Benchmark for Instance-Level Recognition and Retrieval</a> introduces the Google Landmarks Dataset v2 (GLDv2), a new benchmark for large-scale, fine-grained instance recognition and image retrieval in the domain of human-made and natural landmarks. GLDv2 is the largest such dataset to date by a large margin, including over 5M images and 200k distinct instance labels. Its test set consists of 118k images with ground truth annotations for both the retrieval and recognition tasks.   </li><li><a href="https://ai.googleblog.com/2020/02/enhancing-research-communitys-access-to.html">Enhancing the Research Community’s Access to Street View Panoramas for Language Grounding Tasks</a> describes a new open dataset to allow researchers to compare techniques for language-grounded navigation tasks or other tasks that rely on Street View panoramas, using a well-known set of data so that comparisons between different techniques can be done more easily. </li></ul><p><b>Research Community Interaction</b><br />We are proud to enthusiastically support and participate in the broader research community. In 2020, Google researchers presented over 500 papers at leading research conferences, additionally serving on program committees, organizing workshops, tutorials and numerous other activities aimed at collectively progressing the state of the art in the field. To learn more about our contributions to some of the larger research conferences this year, please see our blog posts for <a href="https://ai.googleblog.com/2020/04/google-at-iclr-2020.html">ICLR 2020</a>, <a href="http://ai.googleblog.com/2020/06/google-at-cvpr-2020.html">CVPR 2020</a>, <a href="http://ai.googleblog.com/2020/07/google-at-acl-2020.html">ACL 2020</a>, <a href="http://ai.googleblog.com/2020/07/google-at-icml-2020.html">ICML 2020</a>, <a href="http://ai.googleblog.com/2020/08/google-at-eccv-2020.html">ECCV 2020</a> and <a href="http://ai.googleblog.com/2020/12/google-at-neurips-2020.html">NeurIPS 2020</a>. </p><p>In 2020 we supported external research with $37M in funding, including $8.5M in COVID research, $8M in research inclusion and equity, and $2M in responsible AI research. In February, we announced the <a href="https://ai.googleblog.com/2020/02/announcing-2019-google-faculty-research.html">2019 Google Faculty Research Award Recipients</a>, funding research proposals from 150 faculty members throughout the world. Among this group, 27% self-identified as members of historically underrepresented groups within technology. We also announced a new <a href="https://research.google/outreach/research-scholar-program/">Research Scholar Program</a> to support early-career professors who are pursuing research in fields relevant to Google via unrestricted gifts. As we have for more than a decade, we selected a group of incredibly talented PhD student researchers to receive <a href="http://ai.googleblog.com/2020/10/announcing-2020-google-phd-fellows.html">Google PhD Fellowships</a>, which provides funding for graduate studies, as well as mentorship as they pursue their research, and opportunities to interact with other Google PhD Fellows. </p><p>We are also expanding the ways that we support inclusion and bring new voices into the field of computer science. In 2020, we created a new <a href="https://ai.googleblog.com/2020/10/announcing-2020-award-for-inclusion.html">Award for Inclusion Research</a> program that supports academic research in computing and technology addressing the needs of underrepresented populations. In the inaugural set of awards, we selected 16 proposals for funding with 25 principal investigators, focused on topics around diversity and inclusion, algorithmic bias, education innovation, health tools, accessibility, gender bias, AI for social good, security, and social justice. We additionally partnered with the <a href="https://cahsi.utep.edu/">Computing Alliance of Hispanic-Serving Institutions</a> (CAHSI) and the <a href="https://cmd-it.org/program/current/flip-alliance/">CMD-IT Diversifying Future Leadership in the Professoriate Alliance </a>(FLIP) to create an <a href="https://blog.google/outreach-initiatives/education/new-awards-support-future-leaders-computing-research/">award program for doctoral students from traditionally underrepresented backgrounds</a> to support the last year of the completion of the dissertation requirements.  </p><p>In 2019, <a href="https://blog.google/outreach-initiatives/education/cs-research-mentorship/">Google’s CS Research Mentorship Program</a> (CSRMP) helped provide mentoring to 37 undergraduate students to introduce them to conducting computer science research. Based on the success of the program in 2019/2020, we’re excited to greatly expand this <a href="https://research.google/outreach/csrmp/">program</a> in 2020/2021 and will have hundreds of Google researchers mentoring hundreds of undergraduate students in order to encourage more people from underrepresented backgrounds to pursue computer science research careers. Finally, in October we provided <a href="https://blog.google/outreach-initiatives/education/explorecsr-puts-students-path-computer-science-research/">exploreCSR awards</a> to 50 institutions around the world for the 2020 academic year. These awards fund faculty to host workshops for undergraduates from underrepresented groups in order to encourage them to pursue CS research. </p><p><b>Looking Forward to 2021 and Beyond</b><br />I’m excited about what’s to come, from our technical work on next-generation AI models, to the very human work of growing our community of researchers.  </p><p>We’ll keep ensuring our research is done responsibly and has a positive impact, using our <a href="https://blog.google/technology/ai/update-work-ai-responsible-innovation/">AI Principles</a> as a guiding framework and applying particular scrutiny to topics that can have broad societal impact. This post covers just a few of <a href="https://research.google/pubs/?collection=responsible-ai">the many papers on responsible AI</a> that Google published in the past year. While pursuing our research, we’ll focus on: </p><ul><li><b><em>Promoting research integrity:</em></b>  We’ll make sure Google keeps conducting a wide range of research in an appropriate manner, and provides comprehensive, scientific views on a variety of challenging, interesting topics.   </li><li><b><em>Responsible AI development:</em></b>  Tackling tough topics will remain core to our work, and Google will continue creating new ML algorithms to make machine learning more efficient and accessible, developing approaches to combat unfair bias in language models, devising new techniques for ensuring privacy in learning systems, and much more. And importantly, beyond looking at AI development with a suitably critical eye, we’re eager to see what techniques we and others in the community can develop to mitigate risks and make sure new technologies have equitable, positive impacts on society.   </li><li><b><em>Advancing diversity, equity, and inclusion:</em></b>  We care deeply that the people who are building influential products and computing systems better reflect the people using these products all around the world. Our efforts here are both within Google Research, as well as within the wider research and academic communities — we’ll be calling upon the academic and industry partners we work with to advance these efforts together. On a personal level, I am deeply committed to improving representation in computer science, having spent hundreds of hours working towards these goals over the last few years, as well as supporting universities like <a href="https://newsletter.eecs.berkeley.edu/2019/11/hopper-dean-gift/">Berkeley</a>, <a href="https://www.cs.cmu.edu/news/school-computer-science-launches-educational-equity-office-3-million-grant">CMU</a>, <a href="https://www.cs.cornell.edu/information/news/newsitem11347/33-million-gift-hopper-dean-foundation-funds-creation-cis-office">Cornell</a>, <a href="https://focus.gatech.edu/">Georgia Tech</a>, <a href="https://newsroom.howard.edu/newsroom/article/11591/howard-university-receives-4-million-hopper-dean-foundation-gift-expand">Howard</a>, <a href="https://www.cs.washington.edu/diversity/ongoing-activities">UW</a>, and numerous other organizations that work to advance inclusiveness. This is important to me, to Google, and to the broader computer science community. </li></ul><p>Finally, looking ahead to the year, I’m particularly enthusiastic about the possibilities of building more general-purpose machine learning models that can handle a variety of modalities and that can automatically learn to accomplish new tasks with very few training examples. Advances in this area will empower people with dramatically more capable products, bringing better translation, speech recognition, language understanding and creative tools to billions of people all around the world.<em> </em>This kind of exploration and impact is what keeps us excited about our work! </p><p><b>Acknowledgements</b><br /><em>Thanks to Martin Abadi, Marc Bellemare, Elie Bursztein, Zhifeng Chen, Ed Chi, Charina Chou, Katherine Chou, Eli Collins, Greg Corrado, Corinna Cortes, Tiffany Deng, Tulsee Doshi, Robin Dua, Kemal El Moujahid, Aleksandra Faust, Orhan Firat, Jen Gennai, Till Hennig, Ben Hutchinson, Alex Ingerman, Tomáš Ižo, Matthew Johnson, Been Kim, Sanjiv Kumar, Yul Kwon, Steve Langdon, James Laudon, Quoc Le, Yossi Matias, Brendan McMahan, Aranyak Mehta, Vahab Mirrokni, Meg Mitchell, Hartmut Neven, Mohammad Norouzi, Timothy Novikoff, Michael Piatek, Florence Poirel, David Salesin, Nithya Sambasivan, Navin Sarma, Tom Small, Jascha Sohl-Dickstein, Zak Stone, Rahul Sukthankar, Mukund Sundararajan, Andreas Terzis, Sergei Vassilvitskii, Vincent Vanhoucke, and Leslie Yeh and others for helpful feedback and for drafting portions of this post, and to the entire Research and Health communities at Google for everyone’s contributions towards this work.</em></p><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/blogspot/gJZg?a=80Gya-tEqYI:yNcoR7tTIDI:yIl2AUoC8zA"><img border="0" src="http://feeds.feedburner.com/~ff/blogspot/gJZg?d=yIl2AUoC8zA" /></a>
</div><img alt="" height="1" src="http://feeds.feedburner.com/~r/blogspot/gJZg/~4/80Gya-tEqYI" width="1" />

### error read: http://www.bigdatainterview.com/feed/

### [Paper: Deep learning and computer vision will transform entomology](https://www.reddit.com/r/DeepLearningPapers/comments/kvztel/paper_deep_learning_and_computer_vision_will/)

 <!-- SC_OFF --><div class="md"><p>Maybe some of you will find the application of deep learning in ecology/entomology interesting.</p> <p>Entomology is not just dusty old museum collections and insects on needles (nothing wrong with either). It is also cutting-edge technology, big data and AI. The vast number of insect species and the challenging task of studying them makes entomology the perfect playground for collaborative efforts, in this case between biologists, statisticians, and mechanical, electrical and software engineers. In the paper, we demonstrate the relevance of high-tech solutions in entomological research.</p> <p>&#x200b;</p> <p><a href="https://www.pnas.org/content/118/2/e2002545117">Paper: Deep learning and computer vision will transform entomology</a></p> <p>&#x200b;</p> <p><a href="https://preview.redd.it/go6n8yzymya61.png?width=1145&amp;format=png&amp;auto=webp&amp;s=52d9dee24bfd8d93f241e7cd340fdbbb1ae7f0e9">https://preview.redd.it/go6n8yzymya61.png?width=1145&amp;format=png&amp;auto=webp&amp;s=52d9dee24bfd8d93f241e7cd340fdbbb1ae7f0e9</a></p> <p>Disclaimer: Co-author of paper</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/HjalteM"> /u/HjalteM </a> <br /> <span><a href="https://www.reddit.com/r/DeepLearningPapers/comments/kvztel/paper_deep_learning_and_computer_vision_will/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/DeepLearningPapers/comments/kvztel/paper_deep_learning_and_computer_vision_will/">[comments]</a></span>

### error read: https://www.codesky.me/feed/

### [《今日学术视野(2021.1.13)》网页链接](https://weibo.com/1402400261/JCVssfneN)

### [早！[太阳] #早安# [图片]](https://weibo.com/1402400261/JCVqAsCAh)

### [【How to Simulate I/O Faults at Runtime?】网页链接 如何在运行时模拟I / O故障？源代码GitHub托管地址：网页链接  网路冷眼技术分享 #科技暖心季# [图片][图...](https://weibo.com/1715118170/JCVzuDtSW)

### [【Software Testing Best Practices FAQ】网页链接 软件测试最佳实践常见问题 。网路冷眼技术分享 #科技暖心季# [图片]](https://weibo.com/1715118170/JCVnxDnqi)

### [世界上有哪些独特而美丽的旅行景点？](https://daily.zhihu.com/story/9731966)

### [为什么有些人冬天不每天洗澡？可能是「怕痒」](https://daily.zhihu.com/story/9731942)

### [孩子怕黑不敢自己睡，家长应该如何应对？](https://daily.zhihu.com/story/9731960)

### [为什么刘备那么幸运，结拜了两个都是「万人敌」的兄弟？](https://daily.zhihu.com/story/9731950)

### [大脑自闭了，为什么是肠道的锅？](https://daily.zhihu.com/story/9731949)

### [瞎扯 · 如何正确地吐槽](https://daily.zhihu.com/story/9731901)

### [青年图摘0113！有本事抽我啊](https://qingniantuzhai.com/qing-nian-tu-zhai-0113-3/)

 <!--kg-card-begin: markdown--><img alt="青年图摘0113！有本事抽我啊" src="https://qingniantuzhai.com/content/images/2021/01/00893JKXly1gml1z8w5d0j30dw0ii751_---.jpg" /><p>【1】突然可爱<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx1.sinaimg.cn/mw1024/7283506bly1g04yqdp05kg205m0a0npi.gif" /></p>
<p>【2】只要我喝的够快就淹不死<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx3.sinaimg.cn/mw1024/00893JKXly1gml6eaavxqg3074074x6w.gif" /></p>
<p>【3】司机:这是什么魔术？<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw1024/00893JKXly1gml3iw8uzag30a907inpk.gif" /></p>
<p>【4】大象，大象，你的鼻子为什么那么长<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw1024/81fa7475gy1gml3c1m0vag208q0bokjs.gif" /></p>
<p>【5】你想来我家看看裤裆里的鸟吗<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw1024/81fa7475gy1gml3c4gt0ng206u0c44qs.gif" /></p>
<p>【6】这也太好玩了 冰棒生成器<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw1024/81fa7475gy1gml3c996fcg206s0by7wn.gif" /></p>
<p>【7】我要看切开的样子！！！！<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx3.sinaimg.cn/mw1024/81fa7475gy1gml3c92sekg205w0agnpk.gif" /></p>
<p>【8】有本事抽我啊<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/00893JKXly1gml1z8w5d0j30dw0ii751.jpg" /></p>
<p>【9】饿死鬼托生的。<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw1024/007ee61jly1gml0p3qzu7g30af08lu14.gif" /></p>
<p>【10】很有年代感<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw600/00893JKXly1gmkxf9j2vgj30cx0mzdic.jpg" /><br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx1.sinaimg.cn/mw600/00893JKXly1gmkxf3gsboj30cw082q4j.jpg" /><br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/00893JKXly1gmkxev23mej30cx0h9taz.jpg" /><br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/00893JKXly1gmkxentjt9j309o0byt9y.jpg" /></p>
<p>【11】走的很安详。<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://ww1.sinaimg.cn/mw600/00814FKVgy1gmkudu04ioj30cs0h2408.jpg" /></p>
<p>【12】这有难度啊老友，成功戒掉的家伙没法给你分享经验<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx3.sinaimg.cn/mw600/00893JKXly1gmkubpihrzj30j615jjuy.jpg" /></p>
<p>【13】巨乘佛法！<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw1024/00893JKXly1gmkub9p2pkg307h0csx6s.gif" /></p>
<p>【14】粮食永动机<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx3.sinaimg.cn/mw1024/0089pNo8ly1gmktv8a168g30dw0af4r4.gif" /></p>
<p>【15】你就说换没换底吧<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx4.sinaimg.cn/mw600/002sWkUBgy1gmkspjq7efj60rw0c244w02.jpg" /><br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/002sWkUBgy1gmkspkdfv0j60wi12zb2902.jpg" /><br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx3.sinaimg.cn/mw600/002sWkUBgy1gmksplaiyyj60wi148b2902.jpg" /></p>
<p>【16】你就说性不性感吧？<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/00893JKXly1gmkslrhxq5j30js14fk1b.jpg" /></p>
<p>【17】这人从来没理过我<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx1.sinaimg.cn/mw600/00893JKXly1gmkslmas9yj30j80li408.jpg" /></p>
<p>【18】姜狗........<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://wx2.sinaimg.cn/mw600/00893JKXly1gmksl9c5nqj30hs0mtdzc.jpg" /></p>
<p>【19】一鹿一个角<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://tvax2.sinaimg.cn/mw1024/83a551acgy1gmkrzlsw99g20hs0i67wu.gif" /></p>
<p>【20】3号马必赢！本汪有内幕消息下注了20根骨头了！<br />
<img alt="青年图摘0113！有本事抽我啊" src="https://tvax3.sinaimg.cn/mw1024/83a551acgy1gmkrnx86hgg207h0dn4r4.gif" /></p>
<!--kg-card-end: markdown-->

### [“头腾”大战硝烟再起](https://www.infoq.cn/article/tCYvF9vFR2hLEu2U1ykR)

### [数据仓库项目中的数据建模和ETL日志体系](https://www.infoq.cn/article/YiWmCJXJTqTQLQKjlGl0)

### [【Understanding Connections and Pools】网页链接 了解连接和池。](https://weibo.com/1715118170/JCWa5cyK9)

### [【Re-Introducing Hash Indexes in PostgreSQL】网页链接 在PostgreSQL中重新引入哈希索引。网路冷眼技术分享 #科技暖心季# [图片][图片][图片][图片][图片]](https://weibo.com/1715118170/JCVXR0TUu)

### [【Security tools from Google】网页链接 Google的安全工具。 网路冷眼技术分享 #科技暖心季# [图片]](https://weibo.com/1715118170/JCVLSCwSn)

### [Daily Hacker News for 2021-01-12](https://www.daemonology.net/hn-daily/2021-01-12.html)

### [闲鱼是如何实践一套完整的埋点自动化验证方案的？](https://www.infoq.cn/article/EmWjojhZubIvBDNQdrvx)

### [留给以太坊的时间不多了](https://www.infoq.cn/article/MoOd1tjpDNx8j5PQLRtA)

### [#小Q分享# 《从 DAU 5 万到用户数破亿，揭秘腾讯会议增长背后的技术实践》10.5 个人开发的一款产品 ，在正式上线两个月后，其日活用户就超过 1000 万。不到一年...](https://weibo.com/1746173800/JCWyoc0Y9)

### [[LG]《Technology Readiness Levels for Machine Learning Systems》A Lavin, C M. Gilligan-Lee, A Visnjic, S Ganju, D Newman, S Ganguly, D Lange, A G Bayd...](https://weibo.com/1402400261/JCWm96216)

### [#绿洲摄影#杭州西湖冬景☁️☁️ 朦胧中透出点点的神秘😳 绿洲 [图片]](https://weibo.com/1715118170/JCWzizYGK)

### [【Load testing is hard and the tools are not great】网页链接 负载测试很困难，工具也不是很好。 网路冷眼技术分享 #科技暖心季# [图片]](https://weibo.com/1715118170/JCWyKmLZM)

### [【Paging and Sorting with Spring Data JPA】网页链接 使用Spring Data JPA进行分页和排序。网路冷眼技术分享 #科技暖心季# [图片][图片][图片][图片][图片]](https://weibo.com/1715118170/JCWmczfS0)

### [派早报：三星发布 Exynos 2100 处理器、高通发布新超声波指纹传感器等](https://sspai.com/post/64547)

### error read: https://www.codesky.me/feed/

### [回不去的 BBS 时代](https://www.v2ex.com/t/744338)

### [Kylin 在 eBay 的成长历程与实践](https://www.infoq.cn/article/56vdaS7pwu2iexe4ukv0)

### [再发两款Serverless产品，金山云云原生版图又拼齐一块](https://www.infoq.cn/article/gTYQfgL6oH3oFhtdXrwC)

### [有奖讨论｜构建基于容器技术，承载数据类有状态工作负载的数据云平台，技术挑战有哪些？](https://www.infoq.cn/article/d7612e169b3a7684628d19096)

### [《猫、爱因斯坦和密码学：我也能看懂的量子通信》后天开奖，欢迎参与！ - 转发 @爱可可-爱生活:&ensp;#抽奖##赠书#活动汇总，参与请转发原微博：《猫、爱因斯坦...](https://weibo.com/1402400261/JCXev7WhN)

### [【Amazon buys 11 Boeing 767s to expand its cargo fleet】网页链接 亚马逊购买11架波音767飞机以扩大其货运机队。 网路冷眼技术分享 #科技暖心季# [图片]](https://weibo.com/1715118170/JCXliv9rd)

### [【Build your own programming language in C++】网页链接 用C ++构建自己的编程语言。网路冷眼技术分享 #科技暖心季# [图片]](https://weibo.com/1715118170/JCWXasOFD)

### [大佬的总结简单明了[笑cry][笑cry][允悲][允悲] - 转发 @玩家老C:&ensp;一个关于TCP连接的（可能）冷知识：客户端显示连接状态切换到了establish，并不表示连接...](https://weibo.com/1642628345/JCWH0pPdA)

### error read: https://www.codesky.me/feed/

### error read: http://www.13775.org/feed/

### error read: http://www.bigdatainterview.com/feed/

### error read: http://www.jintiankansha.me/rss/GEYDCOBUPRRWGMDBGFSDIZTGMM2GCZRVMQZGGNRQHBRTQZLEME4TQYLFGJRDKZBTGI2TSZJUGM======

### [一周世界舆论聚焦：对全球抗疫“政治挂帅”的担忧](http://www.ftchinese.com/story/001090962)

### [爱看书的习惯如何才能持久](http://www.ftchinese.com/story/001090934)

### [2021 你还回家过年吗？](https://www.v2ex.com/t/744401)

### [Notion 中文版本要来啦！](https://www.v2ex.com/t/744395)

### [不懂就问，入手手机无线充电器有意义吗](https://www.v2ex.com/t/744120)

### [1月13日新闻茶泡Fan](https://www.cfan.com.cn/2021/0113/134750.shtml)

### [越是让你受不了的事情，越要尽早解决！优秀的人都有一个共同的特点，就是极度的强迫症——我看不惯这么颓废的自己，我受不了自己一事无成，我无法接受这份垃圾工...](https://weibo.com/6543823943/JCXON0BeZ)

### [git tag and git describe a specified path/commits/tags](http://www.cppblog.com/hkingSP/archive/2021/01/13/217569.html)

### [QUIC进入IETF最后征求意见，互联网的又一次巨大飞跃](https://www.infoq.cn/article/gV9MuaQixrQUoSu7su46)

### [【This is The Entire Computer Science Curriculum in 1000 YouTube Videos】网页链接 1000个计算机科学课程YouTube视频，助您完美完成大学计算机科学学业。#科...](https://weibo.com/1715118170/JCXOgzAgH)

### [互联网行业校招「不踩坑」指南](https://sspai.com/post/64458)

### [An Otter RSS Reader – 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS]](https://www.appinn.com/an-otter-rss-reader/)

 <p><strong>An Otter RSS Reader</strong> 是一款新鲜的 RSS 阅读器，通过 iCloud 支持在 Mac、iPhone、iPad 间同步订阅与阅读记录。iOS 版本支持屏幕小组件，简约，在网页视图中浏览信息，还有一个很萌的水獭图标。@<a class="rank-math-link" href="https://www.appinn.com/an-otter-rss-reader/">Appinn</a></p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="An Otter RSS Reader - 支持 iCloud 同步的简约 RSS 阅读器[macOS/iOS]" src="https://img3.appinn.net/images/202101/an-otter-rss-reader.jpg!o" title="An Otter RSS Reader - 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS] 1" /></figure></div>



<p>感谢 <a class="rank-math-link" href="https://t.me/aboutrss/930" target="_blank">ALL About RSS</a> 频道的推荐。</p>



<h2><strong>An Otter RSS Reader</strong></h2>



<p><strong>An Otter RSS Reader</strong> 可以让你在 Mac 与移动设备之间无缝阅读，iPad 上的阅读体验也是挺好的：</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="An Otter RSS Reader - 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS] 1" src="https://img3.appinn.net/images/202101/screenshot-universal.jpg!o" title="An Otter RSS Reader - 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS] 2" /></figure></div>



<p><strong>An Otter RSS Reader</strong> 的功能还有：</p>



<ul><li>通过 iCloud 同步内容</li><li>自动发现订阅源</li><li>Feeds 分组</li><li>在网页视图中阅读文章</li><li>OPML 导入导出</li><li>屏幕小组件（iOS）</li></ul>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="An Otter RSS Reader - 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS] 2" height="446" src="https://img3.appinn.net/images/202101/img_0eae5ca7a881-1_iphone12black_portrait.jpg!o" title="An Otter RSS Reader - 支持 iCloud 同步阅读进度的简约 RSS 阅读器[macOS/iOS] 3" width="236" /></figure></div>



<p><strong>An Otter RSS Reader</strong> 的屏幕小组件会显示现在有新内容的 Feed 数量和总计的文章数量，还有一个可爱的小水獭。另外小组件可编辑仅显示某文件夹里 Feeds 的更新情况。</p>



<h2>An Otter RSS Reader 下载</h2>



<p>An Otter RSS Reader 可以从 <a class="rank-math-link" href="https://apps.apple.com/cn/app/an-otter-rss-reader/id1529696614#?ref=appinn" rel="noopener" target="_blank">App Store</a> 免费安装，Mac、iPhone、iPad 通用版本。</p>
<hr /><h2>相关阅读</h2><ul><li><a href="https://www.appinn.com/feedme-for-android/" rel="bookmark" title="Permanent Link: Feedme &#8211; 8大 RSS 阅读器第三方客户端[Android]">Feedme &#8211; 8大 RSS 阅读器第三方客户端[Android]</a></li><li><a href="https://www.appinn.com/mr-otter/" rel="bookmark" title="Permanent Link: Mr.Otter &#8211; 比搜索引擎更方便？搜索 200+ 垂直网站内容">Mr.Otter &#8211; 比搜索引擎更方便？搜索 200+ 垂直网站内容</a></li><li><a href="https://www.appinn.com/rolly-rss-reader-for-android/" rel="bookmark" title="Permanent Link: Rolly RSS Reader &#8211; 实用 RSS 阅读器[Android]">Rolly RSS Reader &#8211; 实用 RSS 阅读器[Android]</a></li><li><a href="https://www.appinn.com/fluent-reader/" rel="bookmark" title="Permanent Link: Fluent Reader &#8211; 开源的桌面 RSS 阅读器[Win/macOS]">Fluent Reader &#8211; 开源的桌面 RSS 阅读器[Win/macOS]</a></li><li><a href="https://www.appinn.com/full-rss-feed/" rel="bookmark" title="Permanent Link: RSS feed 摘要输出轻松全文">RSS feed 摘要输出轻松全文</a></li></ul><hr />
<a href="http://www.appinn.com/copyright/?utm_source=feeds&amp;utm_medium=copyright&amp;utm_campaign=feeds" title="版权声明">&#169;</a>2019 青小蛙 for <a href="http://www.appinn.com/?utm_source=feeds&amp;utm_medium=appinn&amp;utm_campaign=feeds" title="本文来自小众软件">小众软件</a> | <a href="http://www.appinn.com/join-us/?utm_source=feeds&amp;utm_medium=joinus&amp;utm_campaign=feeds" title="加入小众软件">加入我们</a> | <a href="https://meta.appinn.com/c/faxian/?utm_source=feeds&amp;utm_medium=contribute&amp;utm_campaign=feeds" rel="noopener" target="_blank" title="给小众软件投稿">投稿</a> | <a href="http://www.appinn.com/feeds-subscribe/?utm_source=feeds&amp;utm_medium=feedsubscribe&amp;utm_campaign=feeds" target="_blank" title="可以分类订阅小众，Windows/MAC/游戏"><font color="red">订阅指南</font></a><br /> 3659b075e72a5b7b1b87ea74aa7932ff <br />
<a href="https://www.appinn.com/an-otter-rss-reader/#comments" title="to the comments">点击这里留言、和原作者一起评论</a>

### [“云逛”国际大展，CES 2021 奇葩产品精选！](https://segmentfault.com/a/1190000038966279)

### [美国建立国家AI倡议办公室，徽章暗示雄鹰要紧抓神经网络](https://segmentfault.com/a/1190000038965806)

### error read: https://rsshub.app/telegram/channel/tgchinanews

### [辣鸡到处都是微信健康码](https://www.v2ex.com/t/744459)

### [有轻量一点的 win10 吗？现在 8G 的机器 20H2 开机内存占用 2.5G](https://www.v2ex.com/t/744420)

### [拼多多被爆远程删除相册内容](https://www.v2ex.com/t/744281)

### error read: https://rsshub.app/telegram/channel/computer_science_and_programming

### [喜奔！QQ 音乐终于有 Linux 版本了，还顺便拿了个大奖！](https://linux.cn/article-13008-1.html?utm_source=rss&utm_medium=rss)

### [一份处理宕机的应急响应入门指南](https://www.infoq.cn/article/NYDlXIqVy43xLUaWdoqq)

### [【When Amazon Switched from Sun to Linux】网页链接 当Amazon从Sun切换到Linux时。 [图片]](https://weibo.com/1715118170/JCYwslD55)

### [【How to monitor your system dependencies】网页链接 如何监视系统依赖性？](https://weibo.com/1715118170/JCY862Sls)

### error read: http://www.waerfa.com/feed

### error read: http://www.bigdatainterview.com/feed/

### [你们公司是业务说得算，还是技术说得算](https://www.v2ex.com/t/744478)

### [如果不能回家，在京过年，一个人，能怎么过](https://www.v2ex.com/t/744237)

### [使用 Atom 文本编辑器的 5 个理由](https://linux.cn/article-13009-1.html?utm_source=rss&utm_medium=rss)

### [微软发布Linux版Edge](https://www.infoq.cn/article/iwpBa1z8ho5HaNZRpkAt)

### [在特朗普“干掉”TikTok之前，TikTok先出手了](https://www.infoq.cn/article/5DtYU4L0UlZ2fwdYhEcC)

### [基于机器学习的分子动力学模拟获得戈登·贝尔奖](https://www.infoq.cn/article/G8sAXL0bNOQSRqPONiCl)

### [谷歌将逐步淘汰Android Things](https://www.infoq.cn/article/LVHk7OvJzNNWN1VgaLO5)

### [这才是真为梦想窒息的选手[挤眼] [图片]](https://weibo.com/1715118170/JCYNteY3U)

### [大幅提高生产力：你需要了解的十大Jupyter Lab插件](https://www.jiqizhixin.com/articles/2021-01-13-5)

 

### [刚刚，ICLR 2021正式放榜：接收率上升，860篇论文创新高](https://www.jiqizhixin.com/articles/2021-01-13-4)

 

### [Sci-Hub重生了，这回用上了分布式网络](https://www.jiqizhixin.com/articles/2021-01-13-3)

 

### [拿下机器学习公有云服务中国市场份额第一的AI开发平台，到底做对了什么？](https://www.jiqizhixin.com/articles/2021-01-13-2)

 

### [1.6万亿参数的语言模型：谷歌大脑提出Switch Transformer，预训练速度可达T5的7倍](https://www.jiqizhixin.com/articles/2021-01-13)

 

### error read: http://120.53.237.72:1200/zhihu/zhuanlan/paperweekly

### error read: http://www.bigdatainterview.com/feed/

### [小孩子第一个手机推荐买什么手机？](https://www.v2ex.com/t/744518)

### [iMove，一个逻辑可复用的，面向函数的，流程可视化的 JavaScript 工具库。拥有流程可视化、逻辑复用、灵活可扩展等特性。GitHub：网页链接 [图片][图片][图片]](https://weibo.com/5722964389/JCZiRlywS)

### [你熟悉的TDSQL不一样了](https://www.infoq.cn/article/gZm5834ZFsJkV9Wr8umk)

### [Oracle 首席工程师杨晓峰的《Java 核心技术面试精讲》，从大厂面试考察知识点出发，精选 36 道面试题，给出典型回答和考点分析，让你领悟题目考察的关键能力。开...](https://weibo.com/1746173800/JCZiRktza)

### [【隐性神经网络模型文献集锦，包括神经常微分方程、平衡网络，可微优化层等】’awesome-implicit-neural-models - A collection of resources on Implicit learn...](https://weibo.com/1402400261/JCYZyzNuF)

### [#冷眼赠书福利# 转发赠书# 网路冷眼联合@华章图书 @华章计算机科学 送出 5 本《ECharts数据可视化》，截至 1 月 20 日，转发此微博即可参与。本书是一部ECharts...](https://weibo.com/1715118170/JCZ917Xus)

### [分心不是你的错——成人 ADHD 问诊指南](https://sspai.com/post/64519)

### error read: http://www.waerfa.com/feed

### [1、我国建成全球规模最大的通信网络2、西班牙遭遇五十年来最强降雪3、巴西试验显示科兴新冠疫苗总体有效率为 50.4%4、推特和亚马逊下架特朗普 各方质疑科技公司...](https://t.me/tgchinanews/918)

### [📹Wed, 13 Jan 2021 07:29:12 GMT](https://t.me/tgchinanews/917)

### [欧盟计划建立欧版防火墙](https://www.v2ex.com/t/744499)

### [为什么训练数据是自然语言处理的瓶颈？](https://www.infoq.cn/article/el4T76D4Ypd0rHlQ4yW0)

### [面向认知，智源研究院联合多家单位发布超大规模新型预训练模型“悟道·文汇”](https://www.infoq.cn/article/Gd0sEkaqyRY58zMpVLOB)

### [想要冬暖夏凉一夜好眠，这是我的空调选购经验](https://sspai.com/post/64520)

### [我的WiFi卡片 – 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？](https://www.appinn.com/my-wifi-sign-online/)

 <p><strong>我的WiFi卡片</strong>是一款简单易用的生成可扫描的 Wi-Fi 密码信息二维码的在线服务。可直接使用手机相机直接扫描 <strong>我的WiFi卡片</strong>，就能连接至对应 Wi-Fi，而无需输入密码。@<a class="rank-math-link" href="https://www.appinn.com/my-wifi-sign-online/">Appinn</a></p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个 Wi-Fi 密码二维码？" src="https://img3.appinn.net/images/202101/mywifiqccode.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 1" /></figure></div>



<p>这是一个真实的故事。</p>



<p>前几日青小蛙接到了远方家里人的微信语言，询问家里的 Wi-Fi 密码是多少，因为来了客人，连不上 Wi-Fi，这个故事似乎没有结束。</p>



<p>两天前 @<a href="https://meta.appinn.net/u/SeKugo" rel="noopener" target="_blank">SeKugo</a> 同学分享了一个帖子：<a class="rank-math-link" href="https://meta.appinn.net/t/topic/21426" rel="noopener" target="_blank">浏览网络时遇到的小惊喜</a>，里面提到了这款服务：</p>



<h2>我的WIFI卡片</h2>



<p>创建一张 A4 大小的卡片便于下载和打印，上面包含你的 WiFi 信息和可供手机扫描连接 WiFi 的二维码。</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 1" src="https://img3.appinn.net/images/202101/screen-appinn2021-01-13_15_51_48.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 2" /></figure></div>



<p>青小蛙灵机一动，这不就是解决家里 Wi-Fi 信息的终极解决方案么？</p>



<p>能读到这篇文章的同学，都会觉得用手机连接 Wi-Fi 是一件理所应当，再平常不过的事情，但从青小蛙每次回家，每次都能遇到帮人连接 Wi-Fi 这件事情来看，对一些人来说，为手机连接 Wi-Fi 并不是一件容易的事情。或许为了学习微信已经精疲力尽，或者习惯了语音输入的他们，在输入密码时看不清键盘。</p>



<p>但总之，这是一件不够友好，不够优雅的事情。</p>



<p>而 <strong>我的WiFi卡片</strong> 解决的问题，不就是这个么？</p>



<p>其实并不需要把这张卡片真正打印出来，做好后，将这个 PDF 直接发到父母的微信中，告诉他们：如果有人要来连 Wi-Fi，就让他们<strong>用相机</strong>（<strong>用相机</strong>（<strong>用相机</strong>））扫码，注意不是微信啊，然后就能连上 Wi-Fi 了。</p>



<p>为此，青小蛙特意测试了几款主流的手机，直接使用相机扫码的效果：</p>



<div class="wp-block-columns">
<div class="wp-block-column">
<figure class="wp-block-image size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 2" src="https://img3.appinn.net/images/202101/photo_2021-01-13_16-17-39.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 3" /></figure>



<figure class="wp-block-image size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 3" src="https://img3.appinn.net/images/202101/photo_2021-01-13_16-17-09.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 4" /></figure>
</div>



<div class="wp-block-column">
<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 4" src="https://img3.appinn.net/images/202101/photo_2021-01-13_16-17-40.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 5" /></figure></div>



<figure class="wp-block-image size-large"><img alt="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 5" src="https://img3.appinn.net/images/202101/photo_2021-01-13_16-16-44.jpg!o" title="我的WiFi卡片 - 为什么要在家中放个带 Wi-Fi 密码信息的二维码卡片？ 6" /></figure>
</div>
</div>



<p>青小蛙测试了一下，比较新一些的 Android 设备，都是可以扫码的，有些设备需要自带的扫一扫功能才可以扫描。</p>



<p>不过就算扫码失败，卡片上还标记了密码，再也不用对着语音说英文了（abcd 的 d&#8230;），有过这个经历的都懂 <img alt="😂" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f602.png" style="height: 1em;" /></p>



<p>真的是，有备无患。</p>



<p>可以直接前往<a class="rank-math-link" href="https://www.mywifisign.com/zh-hans?ref=appinn" rel="noopener" target="_blank">我的WiFi卡片官网</a>生成卡片，也可以前往 <a class="rank-math-link" href="https://meta.appinn.net/t/topic/21426" rel="noopener" target="_blank">@<strong>SeKugo</strong> 的帖子</a>，遇见小惊喜。</p>
<hr /><h2>相关阅读</h2><ul><li><a href="https://www.appinn.com/high-sign/" rel="bookmark" title="Permanent Link: High Sign &#8211; 开源鼠标手势[.net]">High Sign &#8211; 开源鼠标手势[.net]</a></li><li><a href="https://www.appinn.com/bzeek-wifi/" rel="bookmark" title="Permanent Link: Bzeek &#8211; 将无线网卡变成 WiFi 热点">Bzeek &#8211; 将无线网卡变成 WiFi 热点</a></li><li><a href="https://www.appinn.com/wifi-channel-select/" rel="bookmark" title="Permanent Link: 让 Wi-Fi 速度跑的比邻居快[Win/Mac/iOS/Android]">让 Wi-Fi 速度跑的比邻居快[Win/Mac/iOS/Android]</a></li><li><a href="https://www.appinn.com/today-wifi/" rel="bookmark" title="Permanent Link: Today WiFi &#8211; 在通知中心显示当前 WiFi 连接[iPad/iPhone]">Today WiFi &#8211; 在通知中心显示当前 WiFi 连接[iPad/iPhone]</a></li><li><a href="https://www.appinn.com/virtual-router-wifi/" rel="bookmark" title="Permanent Link: Virtual Router &#8211; 用无线网卡虚拟出 WiFi 热点">Virtual Router &#8211; 用无线网卡虚拟出 WiFi 热点</a></li></ul><hr />
<a href="http://www.appinn.com/copyright/?utm_source=feeds&amp;utm_medium=copyright&amp;utm_campaign=feeds" title="版权声明">&#169;</a>2019 青小蛙 for <a href="http://www.appinn.com/?utm_source=feeds&amp;utm_medium=appinn&amp;utm_campaign=feeds" title="本文来自小众软件">小众软件</a> | <a href="http://www.appinn.com/join-us/?utm_source=feeds&amp;utm_medium=joinus&amp;utm_campaign=feeds" title="加入小众软件">加入我们</a> | <a href="https://meta.appinn.com/c/faxian/?utm_source=feeds&amp;utm_medium=contribute&amp;utm_campaign=feeds" rel="noopener" target="_blank" title="给小众软件投稿">投稿</a> | <a href="http://www.appinn.com/feeds-subscribe/?utm_source=feeds&amp;utm_medium=feedsubscribe&amp;utm_campaign=feeds" target="_blank" title="可以分类订阅小众，Windows/MAC/游戏"><font color="red">订阅指南</font></a><br /> 3659b075e72a5b7b1b87ea74aa7932ff <br />
<a href="https://www.appinn.com/my-wifi-sign-online/#comments" title="to the comments">点击这里留言、和原作者一起评论</a>

### error read: http://www.bigdatainterview.com/feed/

### [如何获取长期、稳健高收益](http://www.jintiankansha.me/t/hFN4OyYzxx)

### [抱团股要完蛋？“油茅”、“电池茅”短期见顶！新能源泡沫“口水战”又吵起来了！私募大佬怒怼：有泡沫又怎样？新兴产业就应该有长期泡沫](http://www.jintiankansha.me/t/rQex7aP2Uo)

### [一分钟读懂招股书丨美版“花呗”Affirm IPO，你看好吗？](http://www.jintiankansha.me/t/F7jdkoBrZp)

### [我的十条投资不为清单](http://www.jintiankansha.me/t/lF9PMkyOhp)

### [三种 Linux 下的 SSH 图形界面工具](https://linux.cn/article-13010-1.html?utm_source=rss&utm_medium=rss)

### [海外IT老兵谈996：人才不是加班加出来的，期待有企业能站出来破局](https://www.infoq.cn/article/Wc2cx93LSMpbbGdeTzMI)

### [2021，期待已久的苹果VR眼镜可能真的要来了](https://www.infoq.cn/article/usRw5209lzGlqV9wEeqp)

### [🎉快看，适合99%程序员的技术视频合集｜每日一课年卡大促每周 2 、周 5 定时更新小视频，左耳朵耗子、王争、Winter 等真一线名师，不在BAT，也有大牛教你练就...](https://weibo.com/1746173800/JD05zwGwv)

### [代码家：简明数据库史](https://segmentfault.com/a/1190000038969842)

### [【Cheap and simple way to mount a smartphone directly above a laptop display】网页链接 将智能手机直接安装在笔记本电脑显示器上方的便宜简便方法。网路冷...](https://weibo.com/1715118170/JD01hBdtL)